{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDZmp2BO9KnQ"
   },
   "source": [
    "# **Laboratorio 8: Ready, Set, Deploy! üë©‚ÄçüöÄüë®‚ÄçüöÄ**\n",
    "\n",
    "<center><strong>MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos - Oto√±o 2025</strong></center>\n",
    "\n",
    "### Cuerpo Docente:\n",
    "\n",
    "- Profesores: Stefano Schiappacasse, Sebasti√°n Tinoco\n",
    "- Auxiliares: Melanie Pe√±a, Valentina Rojas\n",
    "- Ayudantes: Angelo Mu√±oz, Valentina Z√∫√±iga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdGqUgwX9pGQ"
   },
   "source": [
    "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser√°n revisados\n",
    "\n",
    "- Nombre de alumno 1: Nicol√°s Fuenzalida\n",
    "- Nombre de alumno 2: Ignacio Huenchumil\n",
    "\n",
    "### **Link de repositorio de GitHub:** [Insertar Repositorio](https://github.com/onemoremoka/MDS7202labs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YraSOKrf9yMl"
   },
   "source": [
    "## Temas a tratar\n",
    "\n",
    "- Entrenamiento y registro de modelos usando MLFlow.\n",
    "- Despliegue de modelo usando FastAPI\n",
    "- Containerizaci√≥n del proyecto usando Docker\n",
    "\n",
    "## Reglas:\n",
    "\n",
    "- **Grupos de 2 personas**\n",
    "- Fecha de entrega: 6 d√≠as de plazo con descuento de 1 punto por d√≠a. Entregas Martes a las 23:59.\n",
    "- Instrucciones del lab el viernes a las 16:15 en formato online. Asistencia no es obligatoria, pero se recomienda fuertemente asistir.\n",
    "- <u>Prohibidas las copias</u>. Cualquier intento de copia ser√° debidamente penalizado con el reglamento de la escuela.\n",
    "- Tienen que subir el laboratorio a u-cursos y a su repositorio de github. Labs que no est√©n en u-cursos no ser√°n revisados. Recuerden que el repositorio tambi√©n tiene nota.\n",
    "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser√°n respondidos por este medio.\n",
    "- Pueden usar cualquier material del curso que estimen conveniente.\n",
    "\n",
    "### Objetivos principales del laboratorio\n",
    "\n",
    "- Generar una soluci√≥n a un problema a partir de ML\n",
    "- Desplegar su soluci√≥n usando MLFlow, FastAPI y Docker\n",
    "\n",
    "El laboratorio deber√° ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m√°ximo las funciones optimizadas que nos entrega `pandas`, las cuales vale mencionar, son bastante m√°s eficientes que los iteradores nativos sobre DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D98okEzUE8hb"
   },
   "source": [
    "# **Introducci√≥n**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSiuBfGiFlQM"
   },
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"https://media.giphy.com/media/v1.Y2lkPTc5MGI3NjExODJnMHJzNzlkNmQweXoyY3ltbnZ2ZDlxY2c0aW5jcHNzeDNtOXBsdCZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/AbPdhwsMgjMjax5reo/giphy.gif\" width=\"400\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wPn8R-6u877j"
   },
   "source": [
    "\n",
    "\n",
    "Consumida en la tristeza el despido de Renac√≠n, Smapina ha deca√≠do en su desempe√±o, lo que se ha traducido en un irregular tratamiento del agua. Esto ha implicado una baja en la calidad del agua, llegando a haber algunos puntos de la comuna en la que el vital elemento no es apto para el consumo humano. Es por esto que la sanitaria p√∫blica de la municipalidad de Maip√∫ se ha contactado con ustedes para que le entreguen una urgente soluci√≥n a este problema (a la vez que dejan a Smapina, al igual que Renac√≠n, sin trabajo üòî).\n",
    "\n",
    "El problema que la empresa le ha solicitado resolver es el de elaborar un sistema que les permita saber si el agua es potable o no. Para esto, la sanitaria les ha proveido una base de datos con la lectura de m√∫ltiples sensores IOT colocados en diversas ca√±er√≠as, conductos y estanques. Estos sensores se√±alan nueve tipos de mediciones qu√≠micas y m√°s una etiqueta elaborada en laboratorio que indica si el agua es potable o no el agua.\n",
    "\n",
    "La idea final es que puedan, en el caso que el agua no sea potable, dar un aviso inmediato para corregir el problema. Tenga en cuenta que parte del equipo docente vive en Maip√∫ y su intoxicaci√≥n podr√≠a implicar graves problemas para el cierre del curso.\n",
    "\n",
    "Atributos:\n",
    "\n",
    "1. pH value\n",
    "2. Hardness\n",
    "3. Solids (Total dissolved solids - TDS)\n",
    "4. Chloramines\n",
    "5. Sulfate\n",
    "6. Conductivity\n",
    "7. Organic_carbon\n",
    "8. Trihalomethanes\n",
    "9. Turbidity\n",
    "\n",
    "Variable a predecir:\n",
    "\n",
    "10. Potability (1 si es potable, 0 no potable)\n",
    "\n",
    "Descripci√≥n de cada atributo se pueden encontrar en el siguiente link: [dataset](https://www.kaggle.com/adityakadiwal/water-potability)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-aIr6KegWsjS"
   },
   "source": [
    "# **1. Optimizaci√≥n de modelos con Optuna + MLFlow (2.0 puntos)**\n",
    "\n",
    "El objetivo de esta secci√≥n es que ustedes puedan combinar Optuna con MLFlow para poder realizar la optimizaci√≥n de los hiperpar√°metros de sus modelos.\n",
    "\n",
    "Como a√∫n no hemos hablado nada sobre `MLFlow` cabe preguntarse: **¬°¬øQu√© !\"#@ es `MLflow`?!**\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media.tenor.com/eusgDKT4smQAAAAC/matthew-perry-chandler-bing.gif\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "## **MLFlow**\n",
    "\n",
    "`MLflow` es una plataforma de c√≥digo abierto que simplifica la gesti√≥n y seguimiento de proyectos de aprendizaje autom√°tico. Con sus herramientas, los desarrolladores pueden organizar, rastrear y comparar experimentos, adem√°s de registrar modelos y controlar versiones.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://spark.apache.org/images/mlflow-logo.png\" width=\"350\">\n",
    "</p>\n",
    "\n",
    "Si bien esta plataforma cuenta con un gran n√∫mero de herramientas y funcionalidades, en este laboratorio trabajaremos con dos:\n",
    "1. **Runs**: Registro que constituye la informaci√≥n guardada tras la ejecuci√≥n de un entrenamiento. Cada `run` tiene su propio run_id, el cual sirve como identificador para el entrenamiento en s√≠ mismo. Dentro de cada `run` podremos acceder a informaci√≥n como los hiperpar√°metros utilizados, las m√©tricas obtenidas, las librer√≠as requeridas y hasta nos permite descargar el modelo entrenado.\n",
    "2. **Experiments**: Se utilizan para agrupar y organizar diferentes ejecuciones de modelos (`runs`). En ese sentido, un experimento puede agrupar 1 o m√°s `runs`. De esta manera, es posible tambi√©n registrar m√©tricas, par√°metros y archivos (artefactos) asociados a cada experimento.\n",
    "\n",
    "### **Todo bien pero entonces, ¬øc√≥mo se usa en la pr√°ctica `MLflow`?**\n",
    "\n",
    "Es sencillo! Considerando un problema de machine learning gen√©rico, podemos registrar la informaci√≥n relevante del entrenamiento ejecutando `mlflow.autolog()` antes entrenar nuestro modelo. Veamos este bonito ejemplo facilitado por los mismos creadores de `MLflow`:\n",
    "\n",
    "```python\n",
    "#!pip install mlflow\n",
    "import mlflow # importar mlflow\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "db = load_diabetes()\n",
    "X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)\n",
    "\n",
    "# Create and train models.\n",
    "rf = RandomForestRegressor(n_estimators=100, max_depth=6, max_features=3)\n",
    "\n",
    "mlflow.autolog() # registrar autom√°ticamente informaci√≥n del entrenamiento\n",
    "with mlflow.start_run(): #¬†delimita inicio y fin del run\n",
    "    #¬†aqu√≠ comienza el run\n",
    "    rf.fit(X_train, y_train) # train the model\n",
    "    predictions = rf.predict(X_test) # Use the model to make predictions on the test dataset.\n",
    "    # aqu√≠ termina el run\n",
    "```\n",
    "\n",
    "Si ustedes ejecutan el c√≥digo anterior en sus m√°quinas locales (desde un jupyter notebook por ejemplo) se dar√°n cuenta que en su directorio *root* se ha creado la carpeta `mlruns`. Esta carpeta lleva el tracking de todos los entrenamientos ejecutados desde el directorio root (importante: si se cambian de directorio y vuelven a ejecutar el c√≥digo anterior, se crear√° otra carpeta y no tendr√°n acceso al entrenamiento anterior). Para visualizar estos entrenamientos, `MLflow` nos facilita hermosa interfaz visual a la que podemos acceder ejecutando:\n",
    "\n",
    "```\n",
    "mlflow ui\n",
    "```\n",
    "\n",
    "y luego pinchando en la ruta http://127.0.0.1:5000 que nos retorna la terminal. Veamos en vivo algunas de sus funcionalidades!\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://media4.giphy.com/media/v1.Y2lkPTc5MGI3NjExZXVuM3A5MW1heDFpa21qbGlwN2pyc2VoNnZsMmRzODZxdnluemo2bCZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/3o84sq21TxDH6PyYms/giphy.gif\" width=\"400\">\n",
    "</p>\n",
    "\n",
    "Les dejamos tambi√©n algunos comandos √∫tiles:\n",
    "\n",
    "- `mlflow.create_experiment(\"nombre_experimento\")`: Les permite crear un nuevo experimento para agrupar entrenamientos\n",
    "- `mlflow.log_metric(\"nombre_m√©trica\", m√©trica)`: Les permite registrar una m√©trica *custom* bajo el nombre de \"nombre_m√©trica\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptP_ygr7S04t"
   },
   "source": [
    "## **1.1 Combinando Optuna + MLflow (2.0 puntos)**\n",
    "\n",
    "Ahora que tenemos conocimiento de ambas herramientas, intentemos ahora combinarlas para **m√°s sabor**. El objetivo de este apartado es simple: automatizar la optimizaci√≥n de los par√°metros de nuestros modelos usando `Optuna` y registrando de forma autom√°tica cada resultado en `MLFlow`.\n",
    "\n",
    "Considerando el objetivo planteado, se le pide completar la funci√≥n `optimize_model`, la cual debe:\n",
    "- **Optimizar los hiperpar√°metros del modelo `XGBoost` usando `Optuna`.**\n",
    "- **Registrar cada entrenamiento en un experimento nuevo**, asegur√°ndose de que la m√©trica `f1-score` se registre como `\"valid_f1\"`. No se deben guardar todos los experimentos en *Default*; en su lugar, cada `experiment` y `run` deben tener nombres interpretables, reconocibles y diferentes a los nombres por defecto (por ejemplo, para un run: \"XGBoost con lr 0.1\").\n",
    "- **Guardar los gr√°ficos de Optuna** dentro de una carpeta de artefactos de Mlflow llamada `/plots`.\n",
    "- **Devolver el mejor modelo** usando la funci√≥n `get_best_model` y serializarlo en el disco con `pickle.dump`. Luego, guardar el modelo en la carpeta `/models`.\n",
    "- **Guardar el c√≥digo en `optimize.py`**. La ejecuci√≥n de `python optimize.py` deber√≠a ejecutar la funci√≥n `optimize_model`.\n",
    "- **Guardar las versiones de las librer√≠as utilizadas** en el desarrollo.\n",
    "- **Respalde las configuraciones del modelo final y la importancia de las variables** en un gr√°fico dentro de la carpeta `/plots` creada anteriormente.\n",
    "\n",
    "*Hint: Le puede ser √∫til revisar los par√°metros que recibe `mlflow.start_run`*\n",
    "\n",
    "```python\n",
    "def get_best_model(experiment_id):\n",
    "    runs = mlflow.search_runs(experiment_id)\n",
    "    best_model_id = runs.sort_values(\"metrics.valid_f1\")[\"run_id\"].iloc[0]\n",
    "    best_model = mlflow.sklearn.load_model(\"runs:/\" + best_model_id + \"/model\")\n",
    "\n",
    "    return best_model\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librer√≠as\n",
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import optuna\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funci√≥n auxiliar\n",
    "def get_best_model(experiment_id):\n",
    "    runs = mlflow.search_runs(experiment_id)\n",
    "    best_run_id = runs.sort_values(\"metrics.valid_f1\", ascending=False)[\"run_id\"].iloc[0]\n",
    "    best_model = mlflow.sklearn.load_model(\"runs:/\" + best_run_id + \"/model\")\n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "FTNLPUnm8yzD"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/02 23:49:56 INFO mlflow.tracking.fluent: Experiment with name 'XGBoost_Water_Potability' does not exist. Creating a new experiment.\n",
      "[I 2025-06-02 23:49:57,846] A new study created in memory with name: no-name-9065bbcb-54e3-42e9-b97b-37fdde267646\n",
      "2025/06/02 23:50:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:50:02,712] Trial 0 finished with value: 0.35777126099706746 and parameters: {'n_estimators': 437, 'learning_rate': 0.22648248189516848, 'max_depth': 8, 'subsample': 0.7993292420985183, 'colsample_bytree': 0.5780093202212182, 'gamma': 1.5599452033620265, 'min_child_weight': 1, 'reg_alpha': 8.661761457749352, 'reg_lambda': 6.011150117432088}. Best is trial 0 with value: 0.35777126099706746.\n",
      "2025/06/02 23:50:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:50:07,796] Trial 1 finished with value: 0.0784313725490196 and parameters: {'n_estimators': 737, 'learning_rate': 0.001124579825911934, 'max_depth': 10, 'subsample': 0.9162213204002109, 'colsample_bytree': 0.6061695553391381, 'gamma': 1.8182496720710062, 'min_child_weight': 2, 'reg_alpha': 3.0424224295953772, 'reg_lambda': 5.247564316322379}. Best is trial 0 with value: 0.35777126099706746.\n",
      "2025/06/02 23:50:11 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:50:11,371] Trial 2 finished with value: 0.07086614173228348 and parameters: {'n_estimators': 489, 'learning_rate': 0.005265139631677754, 'max_depth': 7, 'subsample': 0.569746930326021, 'colsample_bytree': 0.6460723242676091, 'gamma': 3.663618432936917, 'min_child_weight': 5, 'reg_alpha': 7.851759613930136, 'reg_lambda': 1.9967378215835974}. Best is trial 0 with value: 0.35777126099706746.\n",
      "2025/06/02 23:50:14 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:50:14,783] Trial 3 finished with value: 0.32198142414860675 and parameters: {'n_estimators': 563, 'learning_rate': 0.029341527565000736, 'max_depth': 3, 'subsample': 0.8037724259507192, 'colsample_bytree': 0.5852620618436457, 'gamma': 0.6505159298527952, 'min_child_weight': 10, 'reg_alpha': 9.656320330745594, 'reg_lambda': 8.08397348116461}. Best is trial 0 with value: 0.35777126099706746.\n",
      "2025/06/02 23:50:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:50:18,300] Trial 4 finished with value: 0.0 and parameters: {'n_estimators': 374, 'learning_rate': 0.0017456037635797405, 'max_depth': 8, 'subsample': 0.7200762468698007, 'colsample_bytree': 0.5610191174223894, 'gamma': 4.951769101112702, 'min_child_weight': 1, 'reg_alpha': 9.093204020787821, 'reg_lambda': 2.587799816000169}. Best is trial 0 with value: 0.35777126099706746.\n",
      "2025/06/02 23:50:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:50:22,152] Trial 5 finished with value: 0.0 and parameters: {'n_estimators': 696, 'learning_rate': 0.005917607170144194, 'max_depth': 7, 'subsample': 0.7733551396716398, 'colsample_bytree': 0.5924272277627636, 'gamma': 9.695846277645586, 'min_child_weight': 8, 'reg_alpha': 9.394989415641891, 'reg_lambda': 8.948273504276488}. Best is trial 0 with value: 0.35777126099706746.\n",
      "2025/06/02 23:50:26 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:50:26,121] Trial 6 finished with value: 0.3563218390804597 and parameters: {'n_estimators': 638, 'learning_rate': 0.19212959255386391, 'max_depth': 3, 'subsample': 0.5979914312095727, 'colsample_bytree': 0.522613644455269, 'gamma': 3.2533033076326436, 'min_child_weight': 4, 'reg_alpha': 2.713490317738959, 'reg_lambda': 8.287375091519294}. Best is trial 0 with value: 0.35777126099706746.\n",
      "2025/06/02 23:50:29 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:50:29,782] Trial 7 finished with value: 0.23809523809523808 and parameters: {'n_estimators': 421, 'learning_rate': 0.0049648810171066555, 'max_depth': 7, 'subsample': 0.5704621124873813, 'colsample_bytree': 0.9010984903770198, 'gamma': 0.7455064367977082, 'min_child_weight': 10, 'reg_alpha': 7.722447692966574, 'reg_lambda': 1.987156815341724}. Best is trial 0 with value: 0.35777126099706746.\n",
      "2025/06/02 23:50:33 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:50:33,450] Trial 8 finished with value: 0.4577114427860696 and parameters: {'n_estimators': 104, 'learning_rate': 0.10471209213501693, 'max_depth': 8, 'subsample': 0.8645035840204937, 'colsample_bytree': 0.8856351733429728, 'gamma': 0.7404465173409036, 'min_child_weight': 4, 'reg_alpha': 1.1586905952512971, 'reg_lambda': 8.631034258755935}. Best is trial 8 with value: 0.4577114427860696.\n",
      "2025/06/02 23:50:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:50:37,154] Trial 9 finished with value: 0.0 and parameters: {'n_estimators': 661, 'learning_rate': 0.006601984958164864, 'max_depth': 3, 'subsample': 0.6554911608578311, 'colsample_bytree': 0.6625916610133735, 'gamma': 7.29606178338064, 'min_child_weight': 7, 'reg_alpha': 8.872127425763265, 'reg_lambda': 4.722149251619493}. Best is trial 8 with value: 0.4577114427860696.\n",
      "2025/06/02 23:50:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:50:40,617] Trial 10 finished with value: 0.22222222222222224 and parameters: {'n_estimators': 118, 'learning_rate': 0.05612788505223878, 'max_depth': 5, 'subsample': 0.968324376628699, 'colsample_bytree': 0.9896117410993797, 'gamma': 6.902470735691453, 'min_child_weight': 3, 'reg_alpha': 0.11114384822711298, 'reg_lambda': 9.693130727540947}. Best is trial 8 with value: 0.4577114427860696.\n",
      "2025/06/02 23:50:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:50:45,186] Trial 11 finished with value: 0.40223463687150834 and parameters: {'n_estimators': 971, 'learning_rate': 0.28583417558947427, 'max_depth': 9, 'subsample': 0.8493715211433202, 'colsample_bytree': 0.7848596544349612, 'gamma': 2.362640564998433, 'min_child_weight': 1, 'reg_alpha': 5.732909776512292, 'reg_lambda': 5.916836359300596}. Best is trial 8 with value: 0.4577114427860696.\n",
      "2025/06/02 23:50:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:50:48,653] Trial 12 finished with value: 0.30379746835443033 and parameters: {'n_estimators': 945, 'learning_rate': 0.0779130969530831, 'max_depth': 10, 'subsample': 0.8768806654636198, 'colsample_bytree': 0.8045369317168723, 'gamma': 2.8573868537735523, 'min_child_weight': 3, 'reg_alpha': 5.973439560055578, 'reg_lambda': 6.596344698169311}. Best is trial 8 with value: 0.4577114427860696.\n",
      "2025/06/02 23:50:52 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:50:52,168] Trial 13 finished with value: 0.48598130841121495 and parameters: {'n_estimators': 997, 'learning_rate': 0.28465333626771555, 'max_depth': 9, 'subsample': 0.865455651151708, 'colsample_bytree': 0.7915712174406057, 'gamma': 0.25549494810543116, 'min_child_weight': 6, 'reg_alpha': 4.970853936108525, 'reg_lambda': 3.9105433983622717}. Best is trial 13 with value: 0.48598130841121495.\n",
      "2025/06/02 23:50:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:50:55,397] Trial 14 finished with value: 0.45989304812834225 and parameters: {'n_estimators': 111, 'learning_rate': 0.08429782858931344, 'max_depth': 5, 'subsample': 0.9980084946806068, 'colsample_bytree': 0.8618649519902001, 'gamma': 0.21271302968900524, 'min_child_weight': 6, 'reg_alpha': 0.8363715867789705, 'reg_lambda': 3.3509767859052797}. Best is trial 13 with value: 0.48598130841121495.\n",
      "2025/06/02 23:50:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:50:58,682] Trial 15 finished with value: 0.19217081850533807 and parameters: {'n_estimators': 241, 'learning_rate': 0.02887400189713075, 'max_depth': 5, 'subsample': 0.9687805796830113, 'colsample_bytree': 0.7242740284450381, 'gamma': 5.3939685217145, 'min_child_weight': 7, 'reg_alpha': 3.0624425729980516, 'reg_lambda': 3.514870513111849}. Best is trial 13 with value: 0.48598130841121495.\n",
      "2025/06/02 23:51:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:51:02,092] Trial 16 finished with value: 0.4318766066838047 and parameters: {'n_estimators': 837, 'learning_rate': 0.11233870541627661, 'max_depth': 5, 'subsample': 0.9898232498406145, 'colsample_bytree': 0.8607349956827239, 'gamma': 0.12073509804772653, 'min_child_weight': 6, 'reg_alpha': 4.520531132638556, 'reg_lambda': 0.13179214380923554}. Best is trial 13 with value: 0.48598130841121495.\n",
      "2025/06/02 23:51:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:51:05,523] Trial 17 finished with value: 0.2068965517241379 and parameters: {'n_estimators': 292, 'learning_rate': 0.03224508303348736, 'max_depth': 6, 'subsample': 0.92076720625875, 'colsample_bytree': 0.7182206884738118, 'gamma': 4.360998335722802, 'min_child_weight': 8, 'reg_alpha': 4.284081702706105, 'reg_lambda': 3.7801446938757186}. Best is trial 13 with value: 0.48598130841121495.\n",
      "2025/06/02 23:51:09 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:51:09,107] Trial 18 finished with value: 0.4414893617021276 and parameters: {'n_estimators': 812, 'learning_rate': 0.013584549387791092, 'max_depth': 4, 'subsample': 0.5075556039920437, 'colsample_bytree': 0.9419437270419531, 'gamma': 1.579513000600563, 'min_child_weight': 6, 'reg_alpha': 1.7958147202805308, 'reg_lambda': 0.5116613237950665}. Best is trial 13 with value: 0.48598130841121495.\n",
      "2025/06/02 23:51:12 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:51:12,329] Trial 19 finished with value: 0.15942028985507248 and parameters: {'n_estimators': 290, 'learning_rate': 0.14614377330006523, 'max_depth': 6, 'subsample': 0.7159288929998385, 'colsample_bytree': 0.8348638762601323, 'gamma': 6.381081622584337, 'min_child_weight': 5, 'reg_alpha': 6.538839629254712, 'reg_lambda': 3.93624614816314}. Best is trial 13 with value: 0.48598130841121495.\n",
      "2025/06/02 23:51:15 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:51:15,742] Trial 20 finished with value: 0.1527272727272727 and parameters: {'n_estimators': 883, 'learning_rate': 0.05579661962184867, 'max_depth': 9, 'subsample': 0.9228536055457716, 'colsample_bytree': 0.7637034075139755, 'gamma': 8.718843434580947, 'min_child_weight': 8, 'reg_alpha': 0.11620961627552973, 'reg_lambda': 7.167190764009184}. Best is trial 13 with value: 0.48598130841121495.\n",
      "2025/06/02 23:51:18 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:51:18,991] Trial 21 finished with value: 0.46859903381642515 and parameters: {'n_estimators': 100, 'learning_rate': 0.11045461813873167, 'max_depth': 9, 'subsample': 0.8650605157262118, 'colsample_bytree': 0.8744660087623367, 'gamma': 0.11517002212437305, 'min_child_weight': 4, 'reg_alpha': 1.0567104105974048, 'reg_lambda': 4.698148342752705}. Best is trial 13 with value: 0.48598130841121495.\n",
      "2025/06/02 23:51:22 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:51:22,333] Trial 22 finished with value: 0.47816091954022993 and parameters: {'n_estimators': 190, 'learning_rate': 0.15094776486466194, 'max_depth': 9, 'subsample': 0.8436663907049443, 'colsample_bytree': 0.9155498972845632, 'gamma': 0.32987898522264575, 'min_child_weight': 4, 'reg_alpha': 1.5174808396099762, 'reg_lambda': 3.0908918526176703}. Best is trial 13 with value: 0.48598130841121495.\n",
      "2025/06/02 23:51:25 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:51:25,585] Trial 23 finished with value: 0.4596577017114914 and parameters: {'n_estimators': 200, 'learning_rate': 0.1707088715520855, 'max_depth': 9, 'subsample': 0.8369834852233986, 'colsample_bytree': 0.9381565858978742, 'gamma': 1.3315566197538717, 'min_child_weight': 4, 'reg_alpha': 2.083736436810865, 'reg_lambda': 4.785577374653782}. Best is trial 13 with value: 0.48598130841121495.\n",
      "2025/06/02 23:51:28 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:51:29,038] Trial 24 finished with value: 0.43927648578811374 and parameters: {'n_estimators': 199, 'learning_rate': 0.29899808614347523, 'max_depth': 10, 'subsample': 0.8886164229091261, 'colsample_bytree': 0.9947869725792463, 'gamma': 2.2061075774955863, 'min_child_weight': 3, 'reg_alpha': 3.8992563832047584, 'reg_lambda': 1.2770315765339708}. Best is trial 13 with value: 0.48598130841121495.\n",
      "2025/06/02 23:51:32 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:51:32,685] Trial 25 finished with value: 0.4694835680751174 and parameters: {'n_estimators': 335, 'learning_rate': 0.051852792862417306, 'max_depth': 9, 'subsample': 0.8175253031490278, 'colsample_bytree': 0.8258223448453486, 'gamma': 0.0037507474637691884, 'min_child_weight': 5, 'reg_alpha': 1.2795852374379066, 'reg_lambda': 2.7003445426356487}. Best is trial 13 with value: 0.48598130841121495.\n",
      "2025/06/02 23:51:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:51:36,179] Trial 26 finished with value: 0.48120300751879697 and parameters: {'n_estimators': 347, 'learning_rate': 0.0519465056956562, 'max_depth': 8, 'subsample': 0.7433618398255862, 'colsample_bytree': 0.8175149007757841, 'gamma': 0.9926072462815818, 'min_child_weight': 5, 'reg_alpha': 2.1249362454967744, 'reg_lambda': 2.6531329117652187}. Best is trial 13 with value: 0.48598130841121495.\n",
      "2025/06/02 23:51:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:51:39,601] Trial 27 finished with value: 0.4364640883977901 and parameters: {'n_estimators': 490, 'learning_rate': 0.01754980756634802, 'max_depth': 8, 'subsample': 0.7500949942496842, 'colsample_bytree': 0.9234724242102427, 'gamma': 1.1240409238374285, 'min_child_weight': 7, 'reg_alpha': 5.2230094150203215, 'reg_lambda': 1.0833540106695065}. Best is trial 13 with value: 0.48598130841121495.\n",
      "2025/06/02 23:51:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:51:42,791] Trial 28 finished with value: 0.4143646408839779 and parameters: {'n_estimators': 217, 'learning_rate': 0.15402354901739382, 'max_depth': 8, 'subsample': 0.684614776160856, 'colsample_bytree': 0.7285545670206393, 'gamma': 2.647171998046792, 'min_child_weight': 5, 'reg_alpha': 3.6405607422696455, 'reg_lambda': 2.7067306581241515}. Best is trial 13 with value: 0.48598130841121495.\n",
      "2025/06/02 23:51:46 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:51:46,162] Trial 29 finished with value: 0.3885714285714285 and parameters: {'n_estimators': 592, 'learning_rate': 0.23697563498331875, 'max_depth': 10, 'subsample': 0.7674084684151696, 'colsample_bytree': 0.6786704820049423, 'gamma': 3.8695043318756452, 'min_child_weight': 9, 'reg_alpha': 2.294427930070675, 'reg_lambda': 4.172691565146936}. Best is trial 13 with value: 0.48598130841121495.\n",
      "2025/06/02 23:51:49 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:51:49,525] Trial 30 finished with value: 0.3872832369942197 and parameters: {'n_estimators': 402, 'learning_rate': 0.04200026035823289, 'max_depth': 9, 'subsample': 0.7866360571585419, 'colsample_bytree': 0.7713540092594425, 'gamma': 1.8548431493113386, 'min_child_weight': 2, 'reg_alpha': 3.407488067494251, 'reg_lambda': 5.579180837990998}. Best is trial 13 with value: 0.48598130841121495.\n",
      "2025/06/02 23:51:53 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:51:53,170] Trial 31 finished with value: 0.4591029023746702 and parameters: {'n_estimators': 320, 'learning_rate': 0.017654437145422246, 'max_depth': 9, 'subsample': 0.8142634472008577, 'colsample_bytree': 0.8218169419011538, 'gamma': 1.118242129188583, 'min_child_weight': 5, 'reg_alpha': 1.720652329351117, 'reg_lambda': 2.8641881724610556}. Best is trial 13 with value: 0.48598130841121495.\n",
      "2025/06/02 23:51:56 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:51:56,833] Trial 32 finished with value: 0.4582338902147971 and parameters: {'n_estimators': 325, 'learning_rate': 0.056635927067925834, 'max_depth': 10, 'subsample': 0.8245354312632488, 'colsample_bytree': 0.8240425047523223, 'gamma': 0.04918009418448854, 'min_child_weight': 6, 'reg_alpha': 0.669944647970607, 'reg_lambda': 1.8798356505240648}. Best is trial 13 with value: 0.48598130841121495.\n",
      "2025/06/02 23:52:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:52:00,118] Trial 33 finished with value: 0.4571428571428572 and parameters: {'n_estimators': 507, 'learning_rate': 0.07422584565028209, 'max_depth': 8, 'subsample': 0.732652028747028, 'colsample_bytree': 0.7987709384223151, 'gamma': 1.812142553060412, 'min_child_weight': 5, 'reg_alpha': 2.5309277926576073, 'reg_lambda': 3.1071876555952493}. Best is trial 13 with value: 0.48598130841121495.\n",
      "2025/06/02 23:52:03 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:52:03,468] Trial 34 finished with value: 0.44938271604938274 and parameters: {'n_estimators': 366, 'learning_rate': 0.13380163554450955, 'max_depth': 9, 'subsample': 0.9050055171402356, 'colsample_bytree': 0.8466743730518109, 'gamma': 0.7899791793832385, 'min_child_weight': 4, 'reg_alpha': 1.6446878390792152, 'reg_lambda': 2.44701743351436}. Best is trial 13 with value: 0.48598130841121495.\n",
      "2025/06/02 23:52:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:52:07,001] Trial 35 finished with value: 0.41040462427745666 and parameters: {'n_estimators': 447, 'learning_rate': 0.012214994656294572, 'max_depth': 7, 'subsample': 0.7977466067980034, 'colsample_bytree': 0.959534053117081, 'gamma': 0.6313981271933148, 'min_child_weight': 5, 'reg_alpha': 7.164965960791453, 'reg_lambda': 4.35001759309731}. Best is trial 13 with value: 0.48598130841121495.\n",
      "2025/06/02 23:52:10 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:52:10,230] Trial 36 finished with value: 0.4976303317535545 and parameters: {'n_estimators': 261, 'learning_rate': 0.20880372899565622, 'max_depth': 8, 'subsample': 0.6900422584096844, 'colsample_bytree': 0.7525057721267319, 'gamma': 1.3990737405900269, 'min_child_weight': 2, 'reg_alpha': 1.3532803917544998, 'reg_lambda': 1.4042514156399621}. Best is trial 36 with value: 0.4976303317535545.\n",
      "2025/06/02 23:52:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:52:13,427] Trial 37 finished with value: 0.46078431372549017 and parameters: {'n_estimators': 156, 'learning_rate': 0.21536675018036835, 'max_depth': 8, 'subsample': 0.6603721293646067, 'colsample_bytree': 0.6896335372035484, 'gamma': 1.7971401308305257, 'min_child_weight': 2, 'reg_alpha': 2.951421729824009, 'reg_lambda': 1.3290541093355146}. Best is trial 36 with value: 0.4976303317535545.\n",
      "2025/06/02 23:52:16 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:52:16,850] Trial 38 finished with value: 0.4478371501272265 and parameters: {'n_estimators': 271, 'learning_rate': 0.19119954025141433, 'max_depth': 7, 'subsample': 0.6841787747408875, 'colsample_bytree': 0.7507449332893651, 'gamma': 3.1948009610684895, 'min_child_weight': 1, 'reg_alpha': 0.61069967700288, 'reg_lambda': 1.8825939948446972}. Best is trial 36 with value: 0.4976303317535545.\n",
      "2025/06/02 23:52:20 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:52:20,215] Trial 39 finished with value: 0.4786729857819905 and parameters: {'n_estimators': 746, 'learning_rate': 0.23373983398084852, 'max_depth': 7, 'subsample': 0.622724332593862, 'colsample_bytree': 0.9142298853611532, 'gamma': 1.202990812425175, 'min_child_weight': 3, 'reg_alpha': 4.884613342700584, 'reg_lambda': 0.7164125040392348}. Best is trial 36 with value: 0.4976303317535545.\n",
      "2025/06/02 23:52:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:52:23,818] Trial 40 finished with value: 0.19014084507042253 and parameters: {'n_estimators': 761, 'learning_rate': 0.002870891248413428, 'max_depth': 7, 'subsample': 0.6332187960515903, 'colsample_bytree': 0.6317799388508927, 'gamma': 2.303335843822355, 'min_child_weight': 2, 'reg_alpha': 5.094955358399847, 'reg_lambda': 0.5047179712435923}. Best is trial 36 with value: 0.4976303317535545.\n",
      "2025/06/02 23:52:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:52:27,317] Trial 41 finished with value: 0.5 and parameters: {'n_estimators': 900, 'learning_rate': 0.24508539960841835, 'max_depth': 8, 'subsample': 0.6155704532219163, 'colsample_bytree': 0.9031830651507519, 'gamma': 1.2050444149292938, 'min_child_weight': 3, 'reg_alpha': 4.789153008312058, 'reg_lambda': 2.269136195657411}. Best is trial 41 with value: 0.5.\n",
      "2025/06/02 23:52:30 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:52:30,857] Trial 42 finished with value: 0.49661399548532736 and parameters: {'n_estimators': 998, 'learning_rate': 0.24888266194099654, 'max_depth': 8, 'subsample': 0.6030809816286418, 'colsample_bytree': 0.8923813574769667, 'gamma': 1.1344686344013795, 'min_child_weight': 3, 'reg_alpha': 4.567702604708707, 'reg_lambda': 1.496058111001141}. Best is trial 41 with value: 0.5.\n",
      "2025/06/02 23:52:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:52:34,404] Trial 43 finished with value: 0.5137614678899083 and parameters: {'n_estimators': 944, 'learning_rate': 0.2957749362936222, 'max_depth': 8, 'subsample': 0.5764779065133137, 'colsample_bytree': 0.899621494470221, 'gamma': 0.8343600588670591, 'min_child_weight': 3, 'reg_alpha': 5.809168840342079, 'reg_lambda': 2.247394164927487}. Best is trial 43 with value: 0.5137614678899083.\n",
      "2025/06/02 23:52:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:52:37,969] Trial 44 finished with value: 0.4513064133016627 and parameters: {'n_estimators': 995, 'learning_rate': 0.29312877861397035, 'max_depth': 8, 'subsample': 0.5636533715817711, 'colsample_bytree': 0.8963977916041121, 'gamma': 1.5452787720628007, 'min_child_weight': 3, 'reg_alpha': 5.686665148819581, 'reg_lambda': 2.2399382849941736}. Best is trial 43 with value: 0.5137614678899083.\n",
      "2025/06/02 23:52:41 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:52:41,679] Trial 45 finished with value: 0.4855769230769231 and parameters: {'n_estimators': 920, 'learning_rate': 0.22314684618506253, 'max_depth': 8, 'subsample': 0.5405902898299421, 'colsample_bytree': 0.9735501681192239, 'gamma': 0.600267682000476, 'min_child_weight': 1, 'reg_alpha': 8.293613164753754, 'reg_lambda': 1.6736696694414}. Best is trial 43 with value: 0.5137614678899083.\n",
      "2025/06/02 23:52:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:52:45,015] Trial 46 finished with value: 0.3934426229508196 and parameters: {'n_estimators': 891, 'learning_rate': 0.18566250295114908, 'max_depth': 8, 'subsample': 0.5891412723862386, 'colsample_bytree': 0.8767974226769008, 'gamma': 2.8619986064447103, 'min_child_weight': 2, 'reg_alpha': 6.369198620426148, 'reg_lambda': 0.058693735648043255}. Best is trial 43 with value: 0.5137614678899083.\n",
      "2025/06/02 23:52:48 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:52:48,534] Trial 47 finished with value: 0.38095238095238093 and parameters: {'n_estimators': 999, 'learning_rate': 0.08921336531027285, 'max_depth': 6, 'subsample': 0.6106077183872978, 'colsample_bytree': 0.5538332346301196, 'gamma': 2.097621825002443, 'min_child_weight': 3, 'reg_alpha': 4.282528791611277, 'reg_lambda': 1.4947170007090045}. Best is trial 43 with value: 0.5137614678899083.\n",
      "2025/06/02 23:52:51 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:52:51,838] Trial 48 finished with value: 0.3363363363363363 and parameters: {'n_estimators': 946, 'learning_rate': 0.12607553645991332, 'max_depth': 7, 'subsample': 0.5352512325800247, 'colsample_bytree': 0.8505382975733271, 'gamma': 3.4218156689824637, 'min_child_weight': 2, 'reg_alpha': 7.265285012027109, 'reg_lambda': 0.9475310596116826}. Best is trial 43 with value: 0.5137614678899083.\n",
      "2025/06/02 23:52:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "[I 2025-06-02 23:52:55,166] Trial 49 finished with value: 0.31804281345565744 and parameters: {'n_estimators': 845, 'learning_rate': 0.26243859836806294, 'max_depth': 8, 'subsample': 0.6416631100384684, 'colsample_bytree': 0.9537554834905927, 'gamma': 5.419834557290687, 'min_child_weight': 3, 'reg_alpha': 5.4148416031519675, 'reg_lambda': 2.0214356654421155}. Best is trial 43 with value: 0.5137614678899083.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizaci√≥n completada. Mejor modelo guardado en /models\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed = 42\n",
    "def optimize_model():\n",
    "    # Cargar y preparar datos\n",
    "    df = pd.read_csv('water_potability.csv')\n",
    "\n",
    "    # Conjunto train y val\n",
    "    X = df.drop('Potability', axis=1)\n",
    "    y = df['Potability']\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Configurar experimento\n",
    "    experiment_name = \"XGBoost_Water_Potability\"\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    # Iniciar run principal\n",
    "    with mlflow.start_run(run_name=\"Optuna_Optimization\") as parent_run:\n",
    "        # Registrar versiones de librer√≠as\n",
    "        # Lista todas las librer√≠as instaladas\n",
    "        requirements = subprocess.check_output(['pip', 'freeze']).decode('utf-8')\n",
    "        mlflow.log_text(requirements, \"requirements.txt\")\n",
    "\n",
    "        mlflow.log_param(\"seed\", seed)\n",
    "        \n",
    "        # Funci√≥n objetivo Optuna\n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.3, log=True),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "                'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "                'gamma': trial.suggest_float('gamma', 0, 10),\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "                'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "                'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
    "                'objective': 'binary:logistic',\n",
    "                'random_state': seed,\n",
    "                'eval_metric': 'logloss', # eliminar?\n",
    "                'n_jobs': -1\n",
    "            }\n",
    "            \n",
    "            # Nombre descriptivo para el run\n",
    "            run_name = f\"XGBoost-lr{params['learning_rate']:.4f}-d{params['max_depth']}\"\n",
    "\n",
    "            # Subrama de otra run, anidamos\n",
    "            with mlflow.start_run(run_name=run_name, nested=True):\n",
    "                model = xgb.XGBClassifier(**params)\n",
    "                model.fit(X_train, y_train)\n",
    "                \n",
    "                y_pred = model.predict(X_valid)\n",
    "                f1 = f1_score(y_valid, y_pred)\n",
    "                \n",
    "                mlflow.log_params(params)\n",
    "                mlflow.log_metric(\"valid_f1\", f1)\n",
    "                mlflow.sklearn.log_model(model, \"model\")\n",
    "                \n",
    "            return f1\n",
    "\n",
    "        # Optimizaci√≥n con Optuna\n",
    "        # Mejor combinaci√≥n de hiperpar√°metros\n",
    "        # maximize para f1-score\n",
    "        # TPEsampler es  algoritmo de muestreo\n",
    "        study = optuna.create_study(direction=\"maximize\", sampler=optuna.samplers.TPESampler(seed=seed))\n",
    "        study.optimize(objective, n_trials=50)\n",
    "        \n",
    "        # Guardar gr√°ficos de Optuna\n",
    "        os.makedirs(\"optuna_plots\", exist_ok=True) # carpeta\n",
    "        plot_optimization_history(study).write_image(\"optuna_plots/optimization_history.png\")\n",
    "        plot_param_importances(study).write_image(\"optuna_plots/param_importances.png\")\n",
    "        mlflow.log_artifacts(\"optuna_plots\", artifact_path=\"plots\")\n",
    "        \n",
    "        # Obtener y guardar mejor modelo\n",
    "        experiment_id = mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
    "        best_model = get_best_model(experiment_id)\n",
    "\n",
    "        os.makedirs(\"models\", exist_ok=True) # carpeta modelos\n",
    "        with open(\"models/best_model.pkl\", \"wb\") as f:\n",
    "            pickle.dump(best_model, f) # serializarlo y lo guarda\n",
    "        \n",
    "        # Guardar configuraci√≥n e importancia de caracter√≠sticas\n",
    "        best_params = best_model.get_params()\n",
    "        with open(\"best_params.json\", \"w\") as f:\n",
    "            json.dump(best_params, f)\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        xgb.plot_importance(best_model)\n",
    "        plt.title(\"Feature Importance\")\n",
    "        plt.savefig(\"feature_importance.png\")\n",
    "        plt.close()\n",
    "        \n",
    "        mlflow.log_artifact(\"best_params.json\", artifact_path=\"plots\")\n",
    "        mlflow.log_artifact(\"feature_importance.png\", artifact_path=\"plots\")\n",
    "        \n",
    "        return best_model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    best_model = optimize_model()\n",
    "    print(\"Optimizaci√≥n completada. Mejor modelo guardado en /models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tL2iG18289j9"
   },
   "source": [
    "# **2. FastAPI (2.0 puntos)**\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://media3.giphy.com/media/YQitE4YNQNahy/giphy-downsized-large.gif\" width=\"500\">\n",
    "</div>\n",
    "\n",
    "Con el modelo ya entrenado, la idea de esta secci√≥n es generar una API REST a la cual se le pueda hacer *requests* para as√≠ interactuar con su modelo. En particular, se le pide:\n",
    "\n",
    "- Guardar el c√≥digo de esta secci√≥n en el archivo `main.py`. Note que ejecutar `python main.py` deber√≠a levantar el servidor en el puerto por defecto.\n",
    "- Defina `GET` con ruta tipo *home* que describa brevemente su modelo, el problema que intenta resolver, su entrada y salida.\n",
    "- Defina un `POST` a la ruta `/potabilidad/` donde utilice su mejor optimizado para predecir si una medici√≥n de agua es o no potable. Por ejemplo, una llamada de esta ruta con un *body*:\n",
    "\n",
    "```json\n",
    "{\n",
    "   \"ph\":10.316400384553162,\n",
    "   \"Hardness\":217.2668424334475,\n",
    "   \"Solids\":10676.508475429378,\n",
    "   \"Chloramines\":3.445514571005745,\n",
    "   \"Sulfate\":397.7549459751925,\n",
    "   \"Conductivity\":492.20647361771086,\n",
    "   \"Organic_carbon\":12.812732207582542,\n",
    "   \"Trihalomethanes\":72.28192021570328,\n",
    "   \"Turbidity\":3.4073494284238364\n",
    "}\n",
    "```\n",
    "\n",
    "Su servidor deber√≠a retornar una respuesta HTML con c√≥digo 200 con:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"potabilidad\": 0 # respuesta puede variar seg√∫n el clasificador que entrenens\n",
    "}\n",
    "```\n",
    "\n",
    "**`HINT:` Recuerde que puede utilizar [http://localhost:8000/docs](http://localhost:8000/docs) para hacer un `POST`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSausqDJ9CQh"
   },
   "source": [
    "# **3. Docker (2 puntos)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fNmC483flS00"
   },
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"https://miro.medium.com/v2/resize:fit:1400/1*9rafh2W0rbRJIKJzqYc8yA.gif\" width=\"500\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "niMA_qsCjqlv"
   },
   "source": [
    "Tras el √©xito de su aplicaci√≥n web para generar la salida, Smapina le solicita que genere un contenedor para poder ejecutarla en cualquier computador de la empresa de agua potable.\n",
    "\n",
    "## **3.1 Creaci√≥n de Container (1 punto)**\n",
    "\n",
    "Cree un Dockerfile que use una imagen base de Python, copie los archivos del proyecto e instale las dependencias desde un `requirements.txt`. Con esto, construya y ejecute el contenedor Docker para la API configurada anteriormente. Entregue el c√≥digo fuente (incluyendo `main.py`, `requirements.txt`, y `Dockerfile`) y la imagen Docker de la aplicaci√≥n. Para la dockerizaci√≥n, aseg√∫rese de cumplir con los siguientes puntos:\n",
    "\n",
    "1. **Generar un archivo `.dockerignore`** que ignore carpetas y archivos innecesarios dentro del contenedor.\n",
    "2. **Configurar un volumen** que permita la persistencia de los datos en una ruta local del computador.\n",
    "3. **Exponer el puerto** para acceder a la ruta de la API sin tener que entrar al contenedor directamente.\n",
    "4. **Incluir im√°genes en el notebook** que muestren la ejecuci√≥n del contenedor y los resultados obtenidos.\n",
    "5. **Revisar y comentar los recursos utilizados por el contenedor**. Analice si los contenedores son livianos en t√©rminos de recursos.\n",
    "\n",
    "## **3.2 Preguntas de Smapina (1 punto)**\n",
    "Tras haber experimentado con Docker, Smapina desea profundizar m√°s en el tema y decide realizarle las siguientes consultas:\n",
    "\n",
    "- ¬øC√≥mo se diferencia Docker de una m√°quina virtual (VM)?\n",
    "- ¬øCu√°l es la diferencia entre usar Docker y ejecutar la aplicaci√≥n directamente en el sistema local?\n",
    "- ¬øC√≥mo asegura Docker la consistencia entre diferentes entornos de desarrollo y producci√≥n?\n",
    "- ¬øC√≥mo se gestionan los vol√∫menes en Docker para la persistencia de datos?\n",
    "- ¬øQu√© son Dockerfile y docker-compose.yml, y cu√°l es su prop√≥sito?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8xJ_ZK1IfnZW"
   },
   "source": [
    "# Conclusi√≥n\n",
    "\n",
    "√âxito!\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://i.pinimg.com/originals/55/f5/fd/55f5fdc9455989f8caf7fca7f93bd96a.gif\" width=\"500\">\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
