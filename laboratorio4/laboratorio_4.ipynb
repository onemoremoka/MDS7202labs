{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "ac9155b9f5e04400957a6f8bb3f6610c",
        "deepnote_cell_type": "markdown",
        "id": "2v2D1coL7I8i"
      },
      "source": [
        "<h1><center>Laboratorio 4: La solicitud de Sergio ü§ó</center></h1>\n",
        "\n",
        "<center><strong>MDS7202: Laboratorio de Programaci√≥n Cient√≠fica para Ciencia de Datos - Oto√±o 2025</strong></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "d3d6f6d405c54dbe985a5f4b3e4f9120",
        "deepnote_cell_type": "markdown",
        "id": "YxdTmIPD7L_x"
      },
      "source": [
        "### Cuerpo Docente:\n",
        "\n",
        "- Profesores: Stefano Schiappacasse, Sebasti√°n Tinoco\n",
        "- Auxiliares: Melanie Pe√±a, Valentina Rojas\n",
        "- Ayudantes: Angelo Mu√±oz, Valentina Z√∫√±iga"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "851a7788e8214942863cbd4099064ab2",
        "deepnote_cell_type": "markdown",
        "id": "Y2Gyrj-x7N2L"
      },
      "source": [
        "### Equipo: SUPER IMPORTANTE - notebooks sin nombre no ser√°n revisados\n",
        "\n",
        "- Nombre de alumno 1: Nicol√°s Fuenzalida S√°ez\n",
        "- Nombre de alumno 2: Ignacio Huenchumil Illanes\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "f23a189afdec4e198683308db70e43b7",
        "deepnote_cell_type": "markdown",
        "id": "jQ9skYc57Pxi"
      },
      "source": [
        "### **Link de repositorio de GitHub:** [Insertar Repositorio](https://github.com/onemoremoka/MDS7202labs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "b5318f41cda64d4290a7a548956ed725",
        "deepnote_cell_type": "markdown",
        "id": "1M4PoEWm7S80"
      },
      "source": [
        "## Temas a tratar\n",
        "- Aplicar Pandas para obtener caracter√≠sticas de un DataFrame.\n",
        "- Aplicar Pipelines y Column Transformers.\n",
        "- Utilizar diferentes algoritmos de cluster y ver el desempe√±o.\n",
        "\n",
        "## Reglas:\n",
        "\n",
        "- **Grupos de 2 personas**\n",
        "- Fecha de entrega: 6 d√≠as de plazo con descuento de 1 punto por d√≠a. Entregas Martes a las 23:59.\n",
        "- Instrucciones del lab el viernes a las 16:15 en formato online. Asistencia no es obligatoria, pero se recomienda fuertemente asistir.\n",
        "- <u>Prohibidas las copias</u>. Cualquier intento de copia ser√° debidamente penalizado con el reglamento de la escuela.\n",
        "- Tienen que subir el laboratorio a u-cursos y a su repositorio de github. Labs que no est√©n en u-cursos no ser√°n revisados. Recuerden que el repositorio tambi√©n tiene nota.\n",
        "- Cualquier duda fuera del horario de clases al foro. Mensajes al equipo docente ser√°n respondidos por este medio.\n",
        "- Pueden usar cualquier material del curso que estimen conveniente.\n",
        "\n",
        "### Objetivos principales del laboratorio\n",
        "- Comprender c√≥mo aplicar pipelines de Scikit-Learn para generar clusters.\n",
        "- Familiarizarse con plotly.\n",
        "\n",
        "El laboratorio deber√° ser desarrollado sin el uso indiscriminado de iteradores nativos de python (aka \"for\", \"while\"). La idea es que aprendan a exprimir al m√°ximo las funciones optimizadas que nos entrega `numpy`, las cuales vale mencionar, son bastante m√°s eficientes que los iteradores nativos sobre arreglos (*o tensores*)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "858df483d9e64780a21674afed1d34b8",
        "deepnote_cell_type": "markdown",
        "id": "SuMbiyQZG2Cc"
      },
      "source": [
        "## Descripci√≥n del laboratorio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "403ffe48ec994afda4b91e670a08d0ef",
        "deepnote_cell_type": "markdown",
        "id": "QZsNO4rUrqCz"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://i.pinimg.com/originals/5a/a6/af/5aa6afde8490da403a21601adf7a7240.gif\" width=400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "0303baa17d4546feae8c9b88c58470bf",
        "deepnote_cell_type": "markdown",
        "id": "2o0MPuk8rqCz"
      },
      "source": [
        "En el coraz√≥n de las operaciones de Aerol√≠nea Lucero, Sergio, el gerente de an√°lisis de datos, reuni√≥ a un talentoso equipo de j√≥venes cient√≠ficos de datos para un desaf√≠o crucial: segmentar la base de datos de los clientes. ‚ÄúNuestro objetivo es descubrir patrones en el comportamiento de los pasajeros que nos permitan personalizar servicios y optimizar nuestras campa√±as de marketing,‚Äù explic√≥ Sergio, mientras desplegaba un amplio rango de datos que inclu√≠an desde h√°bitos de compra hasta opiniones sobre los vuelos.\n",
        "\n",
        "Sergio encarg√≥ a los cient√≠ficos de datos la tarea de aplicar t√©cnicas avanzadas de clustering para identificar distintos segmentos de clientes, como los viajeros frecuentes y aquellos que eligen la aerol√≠nea para celebrar ocasiones especiales. La meta principal era entender profundamente c√≥mo estos grupos perciben la calidad y satisfacci√≥n de los servicios ofrecidos por la aerol√≠nea.\n",
        "\n",
        "A trav√©s de un enfoque meticuloso y colaborativo, los cient√≠ficos de datos se abocaron a la tarea, buscando transformar los datos brutos en valiosos insights que permitir√≠an a Aerol√≠nea Lucero no solo mejorar su servicio, sino tambi√©n fortalecer las relaciones con sus clientes mediante una oferta m√°s personalizada y efectiva."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "e78cb41b144041af98928ab26dcfdaa9",
        "deepnote_cell_type": "markdown",
        "id": "hs4KKWF1Hdpo"
      },
      "source": [
        "## Importamos librerias utiles üò∏"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "95a5533cfd6d49cfb9afc111c44d224f",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 15,
        "execution_start": 1714107106552,
        "id": "a4YpMafirqC0",
        "source_hash": null
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import datasets\n",
        "\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SEED = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "acbeab32db6146678e75448dddf43da8",
        "deepnote_cell_type": "markdown",
        "id": "UQOXod4gHhSq"
      },
      "source": [
        "## 1. Estudio de Performance üìà [10 Puntos]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "704b56b978254ad3ae12cdbf58f4832d",
        "deepnote_cell_type": "markdown",
        "id": "Gn5u5ICkrqC2"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://i.pinimg.com/originals/23/b7/6e/23b76e9e77e63c0eec1a7b28372369e3.gif\" width=300>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "d35fbdcc5ef045d6a2822622f0714179",
        "deepnote_cell_type": "markdown",
        "id": "y4Z0jTjtrqC2"
      },
      "source": [
        "Don Sergio les ha encomendado su primera tarea: analizar diversas t√©cnicas de clustering. Su objetivo es entender detalladamente c√≥mo funcionan estos m√©todos en t√©rminos de segmentaci√≥n y eficiencia en tiempo de ejecuci√≥n.\n",
        "\n",
        "Analice y compare el desempe√±o, tiempo de ejecuci√≥n y visualizaciones de cuatro algoritmos de clustering (k-means, DBSCAN, Ward y GMM) aplicados a tres conjuntos de datos, incrementando progresivamente su tama√±o. Utilice Plotly para las gr√°ficas y discuta los resultados tanto cualitativa como cuantitativamente.\n",
        "\n",
        "Uno de los requisitos establecidos por Sergio es que el an√°lisis se lleve a cabo utilizando Plotly; de no ser as√≠, se considerar√° incorrecto. Para facilitar este proceso, se ha proporcionado un c√≥digo de Plotly que puede servir como base para realizar las gr√°ficas. Ap√≥yese en el c√≥digo entregado para efectuar el an√°lisis y tome como referencia la siguiente imagen para realizar los gr√°ficos:\n",
        "\n",
        "<img src='https://gitlab.com/imezadelajara/datos_clase_7_mds7202/-/raw/main/misc_images/Screenshot_2024-04-26_at_9.10.44_AM.png' width=800 />\n",
        "\n",
        "En el gr√°fico se visualizan en dos dimensiones los diferentes tipos de datos proporcionados en `datasets`. Cada columna corresponde a un modelo de clustering diferente, mientras que cada fila representa un conjunto de datos distinto. Cada uno de los gr√°ficos incluye el tiempo en segundos que tarda el an√°lisis y la m√©trica Silhouette obtenida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "37580aab6cef4238a8ce42c50a6d35de",
        "deepnote_cell_type": "markdown",
        "id": "maCUNAvZrqC2"
      },
      "source": [
        "Para ser m√°s espec√≠ficos, usted debe cumplir los siguientes objetivos:\n",
        "1. Generar una funci√≥n que permita replicar el gr√°fico expuesto en la imagen (no importa que los colores calcen). [4 puntos]\n",
        "2. Ejecuta la funci√≥n para un `n_samples` igual a 1000, 5000, 10000. [2 puntos]\n",
        "3. Analice y compare el desempe√±o, tiempo de ejecuci√≥n y visualizaciones de cuatro algoritmos de clustering utilizando las 3 configuraciones dadas en `n_samples`. [4 puntos]\n",
        "\n",
        "\n",
        "> ‚ùó Tiene libertad absoluta de escoger los hiper par√°metros de los cluster, sin embargo, se recomienda verificar el dominio de las variables para realizar la segmentaci√≥n.\n",
        "\n",
        "> ‚ùó Recuerde que es obligatorio el uso de plotly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "7f7c25e366754595b13fc2e8116f65a0",
        "deepnote_cell_type": "code",
        "deepnote_to_be_reexecuted": false,
        "execution_millis": 78,
        "execution_start": 1714107108441,
        "id": "i0IZPGPOrqC3",
        "source_hash": null
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "En la siguiente celda se crean los datos ficticios a usar en la secci√≥n 1 del lab.\n",
        "‚ùóNo realice cambios a esta celda a excepci√≥n de n_samples‚ùó\n",
        "\"\"\"\n",
        "\n",
        "# Datos a utilizar\n",
        "\n",
        "# Configuracion\n",
        "n_samples = 5000 #Este par√°metro si lo pueden modificar\n",
        "\n",
        "def create_data(n_samples):\n",
        "\n",
        "    # Lunas\n",
        "    moons = datasets.make_moons(n_samples=n_samples, noise=0.05, random_state=30)\n",
        "    # Blobs\n",
        "    blobs = datasets.make_blobs(n_samples=n_samples, random_state=172)\n",
        "    # Datos desiguales\n",
        "    transformation = [[0.6, -0.6], [-0.4, 0.8]]\n",
        "    mutated = (np.dot(blobs[0], transformation), blobs[1])\n",
        "\n",
        "    # Generamos Dataset\n",
        "    dataset = {\n",
        "        'moons':{\n",
        "            'x': moons[0], 'classes': moons[1], 'n_cluster': 2\n",
        "        },\n",
        "        'blobs':{\n",
        "            'x': blobs[0], 'classes': blobs[1], 'n_cluster': 3\n",
        "        },\n",
        "        'mutated':{\n",
        "            'x': mutated[0], 'classes': mutated[1], 'n_cluster': 3\n",
        "        }\n",
        "    }\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "data_sets_1000 = create_data(n_samples=1000)\n",
        "data_sets_5000 = create_data(n_samples=5000)\n",
        "data_sets_10000 = create_data(n_samples=10000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se transforma el formato de los datos creados ```data_sets``` hacia un dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generar_dataframes(data_sets):\n",
        "    df_moons = pd.DataFrame(data_sets['moons']['x'], columns=['x1', 'x2'])\n",
        "    df_moons['y_true'] = data_sets['moons']['classes']\n",
        "\n",
        "    df_blobs = pd.DataFrame(data_sets['blobs']['x'], columns=['x1', 'x2'])\n",
        "    df_blobs['y_true'] = data_sets['blobs']['classes']\n",
        "\n",
        "    df_mutated = pd.DataFrame(data_sets['mutated']['x'], columns=['x1', 'x2'])\n",
        "    df_mutated['y_true'] = data_sets['mutated']['classes']\n",
        "\n",
        "    return df_moons, df_blobs, df_mutated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_moons_1000, df_blobs_1000, df_mutated_1000 = generar_dataframes(data_sets_1000)\n",
        "df_moons_5000, df_blobs_5000, df_mutated_5000 = generar_dataframes(data_sets_5000)\n",
        "df_moons_10000, df_blobs_10000, df_mutated_10000 = generar_dataframes(data_sets_10000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y51s6f_UtIkc"
      },
      "source": [
        "**Respuestas:** Silhouette method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def plot_scatter(x, y, labels, time_execute=None, score_silhouette=None):\n",
        "    unique_classes = labels\n",
        "    color_map = {\n",
        "        cls: f'rgb({random.randint(0,255)}, {random.randint(0,255)}, {random.randint(0,255)})'\n",
        "        for cls in unique_classes\n",
        "    }\n",
        "    color_ = labels.map(color_map)\n",
        "    fig = px.scatter(x=x, y=y, color=color_, color_continuous_scale=px.colors.sequential.Viridis)\n",
        "    fig.update_traces(marker=dict(size=5))\n",
        "    fig.update_layout(\n",
        "        autosize=False,\n",
        "        margin=dict(l=0, r=0, t=0, b=0),\n",
        "        showlegend=False\n",
        "    )\n",
        "    fig.add_annotation(\n",
        "        text=f\"{time_execute:.2f} [s]|{score_silhouette:.2f}\",\n",
        "        xref=\"paper\", yref=\"paper\",\n",
        "        x=0.5, y=0.5,\n",
        "        showarrow=False,\n",
        "        font=dict(size=12),\n",
        "        bgcolor=\"rgba(255, 255, 255, 0.8)\",\n",
        "        bordercolor=\"rgba(0, 0, 0, 0.8)\",\n",
        "        borderwidth=1,\n",
        "        borderpad=1,\n",
        "    )\n",
        "    fig.update_xaxes(visible=False)\n",
        "    fig.update_yaxes(visible=False)\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import DBSCAN\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.mixture import GaussianMixture\n",
        "\n",
        "#KMEANS\n",
        "def model_kmeans(data, n_clusters=3, init='k-means++', random_state=0):\n",
        "    time_start = time.time()\n",
        "    model = KMeans(n_clusters=n_clusters, random_state=random_state)\n",
        "    model = model.fit(data)\n",
        "\n",
        "    labels = pd.Series(model.labels_)\n",
        "    score_s = silhouette_score(data, labels)\n",
        "    time_execute = time.time() - time_start\n",
        "    \n",
        "    return labels, model.cluster_centers_, time_execute, score_s\n",
        "\n",
        "# DBSCAN\n",
        "def model_dbscan(data, eps=0.1, min_samples=20):\n",
        "    time_start = time.time()\n",
        "    data = StandardScaler().fit_transform(data)\n",
        "    model = DBSCAN(eps=eps, min_samples=min_samples)\n",
        "    model = model.fit(data)\n",
        "    labels = pd.Series(model.labels_)\n",
        "\n",
        "    time_execute = time.time() - time_start\n",
        "    score_s = silhouette_score(data, labels)\n",
        "    return labels, time_execute, score_s\n",
        "\n",
        "# WARD\n",
        "def model_ward(data, n_clusters=3):\n",
        "    time_start = time.time()\n",
        "    data = StandardScaler().fit_transform(data)\n",
        "    model = AgglomerativeClustering(n_clusters=n_clusters, linkage='ward')\n",
        "    model = model.fit(data)\n",
        "    labels = pd.Series(model.labels_)\n",
        "\n",
        "    time_execute = time.time() - time_start\n",
        "    score_s = silhouette_score(data, labels)\n",
        "    return labels, time_execute, score_s\n",
        "\n",
        "#GMM\n",
        "def model_gmm(data, n_components=3, covariance_type='full', random_state=0):\n",
        "    time_start = time.time()\n",
        "    data = StandardScaler().fit_transform(data)\n",
        "\n",
        "    model = GaussianMixture(n_components=n_components, \n",
        "                            covariance_type=covariance_type, \n",
        "                            random_state=random_state)\n",
        "    model = model.fit(data)\n",
        "    labels = pd.Series(model.predict(data))\n",
        "\n",
        "    time_execute = time.time() - time_start\n",
        "    score_s = silhouette_score(data, labels)\n",
        "    \n",
        "    return labels, time_execute, score_s, model.weights_, model.means_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from plotly.subplots import make_subplots\n",
        "\n",
        "\n",
        "def plot_scatter_full(df_moons, df_blobs, df_mutated, N):\n",
        "    # se crea una grilla de subplots grilla de 3x3\n",
        "    fig = make_subplots(rows=3, cols=4,\n",
        "                        specs=[[{'type': 'scatter'}, {'type': 'scatter'}, {'type': 'scatter'}, {'type': 'scatter'}],\n",
        "                            [{'type': 'scatter'}, {'type': 'scatter'}, {'type': 'scatter'}, {'type': 'scatter'}],\n",
        "                            [{'type': 'scatter'}, {'type': 'scatter'}, {'type': 'scatter'}, {'type': 'scatter'}]],\n",
        "                        subplot_titles=(\"KMEANS\", \"WARD\", \"DBSCAN\", \"GMM\"),\n",
        "                        vertical_spacing=0.05,\n",
        "                        horizontal_spacing=0.05,\n",
        "                        column_widths=[0.2, 0.2, 0.2, 0.2],\n",
        "                        )\n",
        "\n",
        "    fig.update_layout(\n",
        "        height=1000,\n",
        "        width= 1500,\n",
        "        title_text=\"Scatter plots\",\n",
        "        showlegend=False,\n",
        "        title_x=0.5,\n",
        "        title_y=0.95,)\n",
        "\n",
        "    # se calculan los subplots y las m√©tricas individuales\n",
        "    y_pred_moons_kmeans, centers_moons_kmeans, time_moons_kmeans, score_moons_kmeans = model_kmeans(df_moons[['x1', 'x2']], n_clusters=2)\n",
        "    y_pred_blobs_kmeans, centers_blobs_kmeans, time_blobs_kmeans, score_blobs_kmeans = model_kmeans(df_blobs[['x1', 'x2']], n_clusters=3)\n",
        "    y_pred_mutated_kmeans, centers_mutated_kmeans, time_mutated_kmeans, score_mutated_kmeans = model_kmeans(df_mutated[['x1', 'x2']], n_clusters=3)\n",
        "\n",
        "    # dbscan\n",
        "    y_pred_moons_dbscan, time_execute_moons_dbscan, score_silhouette_moons_dbscan = model_dbscan(df_moons[['x1', 'x2']])\n",
        "    y_pred_blobs_dbscan, time_execute_blobs_dbscan, score_silhouette_blobs_dbscan = model_dbscan(df_blobs[['x1', 'x2']])\n",
        "    y_pred_mutated_dbscan, time_execute_mutated_dbscan, score_silhouette_mutated_dbscan = model_dbscan(df_mutated[['x1', 'x2']])\n",
        "\n",
        "    # ward\n",
        "    y_pred_moons_ward, time_execute_moons_ward, score_silhouette_moons_ward = model_ward(df_moons[['x1', 'x2']], n_clusters=2)\n",
        "    y_pred_blobs_ward, time_execute_blobs_ward, score_silhouette_blobs_ward = model_ward(df_blobs[['x1', 'x2']], n_clusters=3)\n",
        "    y_pred_mutated_ward, time_execute_mutated_ward, score_silhouette_mutated_ward = model_ward(df_mutated[['x1', 'x2']], n_clusters=3)\n",
        "\n",
        "    # gmm\n",
        "    y_pred_moons_gmm, time_execute_moons_gmm, score_silhouette_moons_gmm, weights_moons_gmm, means_moons_gmm = model_gmm(df_moons[['x1', 'x2']], n_components=2)\n",
        "    y_pred_blobs_gmm, time_execute_blobs_gmm, score_silhouette_blobs_gmm, weights_blobs_gmm, means_blobs_gmm = model_gmm(df_blobs[['x1', 'x2']], n_components=3)\n",
        "    y_pred_mutated_gmm, time_execute_mutated_gmm, score_silhouette_mutated_gmm, weights_mutated_gmm, means_mutated_gmm = model_gmm(df_mutated[['x1', 'x2']], n_components=3)\n",
        " \n",
        "\n",
        "    def incrustar_fig(fig, data, row, col):\n",
        "        for i in data.data:\n",
        "            fig.add_trace(i, row=row, col=col)\n",
        "        for ann in data.layout.annotations:\n",
        "            fig.add_annotation(ann, row=row, col=col)\n",
        "\n",
        "    # kmeans\n",
        "    subfig_moons_kmeans = plot_scatter(df_moons['x1'],\n",
        "                                    df_moons['x2'],\n",
        "                                    y_pred_moons_kmeans,\n",
        "                                    time_execute=time_moons_kmeans,\n",
        "                                    score_silhouette=score_moons_kmeans\n",
        "                                    )\n",
        "    subfig_blobs_kmeans = plot_scatter(df_blobs['x1'],\n",
        "                                        df_blobs['x2'],\n",
        "                                        y_pred_blobs_kmeans,\n",
        "                                        time_execute=time_blobs_kmeans,\n",
        "                                        score_silhouette=score_blobs_kmeans\n",
        "                                        )\n",
        "    subfig_mutated_kmeans = plot_scatter(df_mutated['x1'],\n",
        "                                        df_mutated['x2'],\n",
        "                                        y_pred_mutated_kmeans,\n",
        "                                        time_execute=time_mutated_kmeans,\n",
        "                                        score_silhouette=score_mutated_kmeans\n",
        "                                        )\n",
        "\n",
        "    incrustar_fig(fig, subfig_moons_kmeans, 1, 1)\n",
        "    incrustar_fig(fig, subfig_blobs_kmeans, 2, 1)\n",
        "    incrustar_fig(fig, subfig_mutated_kmeans, 3, 1)\n",
        "\n",
        "    # ward\n",
        "    subfig_moons_ward = plot_scatter(df_moons['x1'],\n",
        "                                    df_moons['x2'],\n",
        "                                    y_pred_moons_ward,\n",
        "                                    time_execute=time_execute_moons_ward,\n",
        "                                    score_silhouette=score_silhouette_moons_ward\n",
        "                                    )\n",
        "    subfig_blobs_ward = plot_scatter(df_blobs['x1'],\n",
        "                                        df_blobs['x2'],\n",
        "                                        y_pred_blobs_ward,\n",
        "                                        time_execute=time_execute_blobs_ward,\n",
        "                                        score_silhouette=score_silhouette_blobs_ward\n",
        "                                        )\n",
        "    subfig_mutated_ward = plot_scatter(df_mutated['x1'],\n",
        "                                        df_mutated['x2'],\n",
        "                                        y_pred_mutated_ward,\n",
        "                                        time_execute=time_execute_mutated_ward,\n",
        "                                        score_silhouette=score_silhouette_mutated_ward\n",
        "                                        )\n",
        "    incrustar_fig(fig, subfig_moons_ward, 1, 2)\n",
        "    incrustar_fig(fig, subfig_blobs_ward, 2, 2)\n",
        "    incrustar_fig(fig, subfig_mutated_ward, 3, 2)\n",
        "\n",
        "    # dbscan\n",
        "    subfig_moons_dbscan = plot_scatter(df_moons['x1'],\n",
        "                                    df_moons['x2'],\n",
        "                                    y_pred_moons_dbscan,\n",
        "                                    time_execute=time_execute_moons_dbscan,\n",
        "                                    score_silhouette=score_silhouette_moons_dbscan\n",
        "                                    )\n",
        "    subfig_blobs_dbscan = plot_scatter(df_blobs['x1'],\n",
        "                                        df_blobs['x2'],\n",
        "                                        y_pred_blobs_dbscan,\n",
        "                                        time_execute=time_execute_blobs_dbscan,\n",
        "                                        score_silhouette=score_silhouette_blobs_dbscan\n",
        "                                        )\n",
        "    subfig_mutated_dbscan = plot_scatter(df_mutated['x1'],\n",
        "                                        df_mutated['x2'],\n",
        "                                        y_pred_mutated_dbscan,\n",
        "                                        time_execute=time_execute_mutated_dbscan,\n",
        "                                        score_silhouette=score_silhouette_mutated_dbscan\n",
        "                                        )\n",
        "    incrustar_fig(fig, subfig_moons_dbscan, 1, 3)\n",
        "    incrustar_fig(fig, subfig_blobs_dbscan, 2, 3)\n",
        "    incrustar_fig(fig, subfig_mutated_dbscan, 3, 3)\n",
        "\n",
        "    # GMM\n",
        "    subfig_moons_gmm = plot_scatter(df_moons['x1'],\n",
        "                                    df_moons['x2'],\n",
        "                                    y_pred_moons_gmm,\n",
        "                                    time_execute=time_execute_moons_gmm,\n",
        "                                    score_silhouette=score_silhouette_moons_gmm\n",
        "                                    )\n",
        "    subfig_blobs_gmm = plot_scatter(df_blobs['x1'],\n",
        "                                        df_blobs['x2'],\n",
        "                                        y_pred_blobs_gmm,\n",
        "                                        time_execute=time_execute_blobs_gmm,\n",
        "                                        score_silhouette=score_silhouette_blobs_gmm\n",
        "                                        )\n",
        "    subfig_mutated_gmm = plot_scatter(df_mutated['x1'],\n",
        "                                        df_mutated['x2'],\n",
        "                                        y_pred_mutated_gmm,\n",
        "                                        time_execute=time_execute_mutated_gmm,\n",
        "                                        score_silhouette=score_silhouette_mutated_gmm\n",
        "                                        )\n",
        "    incrustar_fig(fig, subfig_moons_gmm, 1, 4)\n",
        "    incrustar_fig(fig, subfig_blobs_gmm, 2, 4)\n",
        "    incrustar_fig(fig, subfig_mutated_gmm, 3, 4)\n",
        "\n",
        "    fig.update_layout(\n",
        "        height=1000,\n",
        "        width=1500,\n",
        "        title_text=f\"Scatter plots n={N})\",\n",
        "        title_font=dict(size=20),\n",
        "        showlegend=False,\n",
        "        title_x=0.5,\n",
        "        title_y=0.99,\n",
        "    )\n",
        "    fig.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_scatter_full(df_moons_1000, df_blobs_1000, df_mutated_1000, 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_scatter_full(df_moons_5000, df_blobs_5000, df_mutated_5000, 5000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_scatter_full(df_moons_10000, df_blobs_10000, df_mutated_10000, 10000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Analice y compare el desempe√±o, tiempo de ejecuci√≥n y visualizaciones de cuatro algoritmos de clustering utilizando las 3 configuraciones dadas en `n_samples`. [4 puntos]\n",
        "\n",
        "**Respuesta**: Se comparan 4 algor``tmos de clustering (Kmeans - ward- DBSCAN - GMM) aplicados sobre tres conjuntos de datos sint√©ticos (moons - blobs - mutated) con diferentes tama√±os de ````n_samples````. Para el caso con n=1000, todos los algoritmos presentan tiempos de ejecuci√≥n bajos, donde el mejor rendimeinto es para GMM y Kmeans, mientras que DBSCAN no logra capturar la estrucutura de ninguno de los clusters sinteticos. A medida que aumentos la cantidad de datos los resultados para los otros modelos se mantiene estable, y DBSCAN experienta una notoria mejora respecto a n=1000, sin embargo aun inferior a los otros metodos. Como se menciono para n=10000 la progresi√≥n en escalabilidad se consolida para GMM que realiza un cluster con un buen coeficiente de siluette en el mismo tiempo (0.06 segundos aprox) que con n=1000. Por otra parte los demas modelos mejoran levemente su eficiencia pero escalando el tiempo exponencialemtne, sobrepasando la barrera de varios segundos.\n",
        "\n",
        "Si bien DBSCAN mostro los peores "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "13c5cb8067d9415f83b3d497954a437a",
        "deepnote_cell_type": "markdown",
        "id": "3mCbZc86rqC6"
      },
      "source": [
        "## 2. An√°lisis de Satisfacci√≥n de Vuelos. [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "fd6e991646b44f50a4b13f01d1542415",
        "deepnote_cell_type": "markdown",
        "id": "JI33m5jbrqC6"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://i.gifer.com/2Hci.gif\" width=400 />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "5742dfbd5a2e43778ff250436bab1005",
        "deepnote_cell_type": "markdown",
        "id": "h5k24znirqC7"
      },
      "source": [
        "Habiendo entendido c√≥mo funcionan los modelos de aprendizaje no supervisado, *Don Sergio* le encomienda estudiar la satisfacci√≥n de pasajeros al haber tomado un vuelo en alguna de sus aerolineas. Para esto, el magnate le dispone del dataset `aerolineas_licer.parquet`, el cual contiene el grado de satisfacci√≥n de los clientes frente a diferentes aspectos del vuelo. Las caracter√≠sticas del vuelo se definen a continuaci√≥n:\n",
        "\n",
        "- *Gender*: G√©nero de los pasajeros (Femenino, Masculino)\n",
        "- *Customer Type*: Tipo de cliente (Cliente habitual, cliente no habitual)\n",
        "- *Age*: Edad actual de los pasajeros\n",
        "- *Type of Travel*: Prop√≥sito del vuelo de los pasajeros (Viaje personal, Viaje de negocios)\n",
        "- *Class*: Clase de viaje en el avi√≥n de los pasajeros (Business, Eco, Eco Plus)\n",
        "- *Flight distance*: Distancia del vuelo de este viaje\n",
        "- *Inflight wifi service*: Nivel de satisfacci√≥n del servicio de wifi durante el vuelo (0:No Aplicable; 1-5)\n",
        "- *Departure/Arrival time convenient*: Nivel de satisfacci√≥n con la conveniencia del horario de salida/llegada\n",
        "- *Ease of Online booking*: Nivel de satisfacci√≥n con la facilidad de reserva en l√≠nea\n",
        "- *Gate location*: Nivel de satisfacci√≥n con la ubicaci√≥n de la puerta\n",
        "- *Food and drink*: Nivel de satisfacci√≥n con la comida y la bebida\n",
        "- *Online boarding*: Nivel de satisfacci√≥n con el embarque en l√≠nea\n",
        "- *Seat comfort*: Nivel de satisfacci√≥n con la comodidad del asiento\n",
        "- *Inflight entertainment*: Nivel de satisfacci√≥n con el entretenimiento durante el vuelo\n",
        "- *On-board service*: Nivel de satisfacci√≥n con el servicio a bordo\n",
        "- *Leg room service*: Nivel de satisfacci√≥n con el espacio para las piernas\n",
        "- *Baggage handling*: Nivel de satisfacci√≥n con el manejo del equipaje\n",
        "- *Check-in service*: Nivel de satisfacci√≥n con el servicio de check-in\n",
        "- *Inflight service*: Nivel de satisfacci√≥n con el servicio durante el vuelo\n",
        "- *Cleanliness*: Nivel de satisfacci√≥n con la limpieza\n",
        "- *Departure Delay in Minutes*: Minutos de retraso en la salida\n",
        "- *Arrival Delay in Minutes*: Minutos de retraso en la llegada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOoIFHpw5xCW"
      },
      "source": [
        "En consideraci√≥n de lo anterior, realice las siguientes tareas:\n",
        "\n",
        "0. Ingeste el dataset a su ambiente de trabajo.\n",
        "\n",
        "1. Seleccione **s√≥lo las variables num√©ricas del dataset**.  Explique qu√© √©fectos podr√≠a causar el uso de variables categ√≥ricas en un algoritmo no supervisado. [2 punto]\n",
        "\n",
        "2. Realice una visualizaci√≥n de la distribuci√≥n de cada variable y analice cada una de estas distribuciones. [2 punto]\n",
        "\n",
        "3. Bas√°ndose en los gr√°ficos, eval√∫e la necesidad de escalar los datos y explique el motivo de su decisi√≥n. [2 puntos]\n",
        "\n",
        "4. Examine la correlaci√≥n entre las variables mediante un correlograma. [2 puntos]\n",
        "\n",
        "5. De acuerdo con los resultados obtenidos en 5, reduzca la dimensionalidad del conjunto de datos a cuatro variables, justificando su elecci√≥n respecto a las variables que decide eliminar. [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tO6tcVBCtxxS"
      },
      "source": [
        "**Respuesta:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzHTZ17xveU_"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 0. Ingeste el dataset a su ambiente de trabajo.\n",
        "df = pd.read_parquet('aerolineas_lucer.parquet')\n",
        "df.info()\n",
        "print(df.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Seleccione **s√≥lo las variables num√©ricas del dataset**.  Explique qu√© √©fectos podr√≠a causar el uso de variables categ√≥ricas en un algoritmo no supervisado. [2 punto]\n",
        "\n",
        "\n",
        "**Respuesta**: Los algoritmos no supervisados clasifican los datos usando medidas de distancia. El uso de variables categ√≥ricas puede incluir relaciones de orden y distancia que no existen realmente en el dataset. Esto puede distoricionar los agrupamientos generados por el algortimo, produciendo resultados que no reflejan el comportamiento de los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_numericas = df.select_dtypes(include='number')\n",
        "df_numericas.drop(columns=['id'], inplace=True) # se elimina el id dado que es una variable numerica nominal.\n",
        "df_numericas.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_numericas.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Realice una visualizaci√≥n de la distribuci√≥n de cada variable y analice cada una de estas distribuciones. [2 punto]\n",
        "\n",
        "**Respuesta**: Las variables de satisfacci√≥n presentan distribuciones aproximadamente sim√©tricas alrededor de la mediana (~3), con un IQR relativamente estrecho [2, 4]. La variable ```SeatComfort``` tiene una calificacio√≥n m√°s variada en un IQE en [2, 5] esto expresa opiniones dividas respecto a la comodidas de los asientos. Por otro lado existe las variables ```baggage handing``` y ```Inflight service``` con IQR m√°s hacia valores mayores, este comportameinto expresa una tendencia generalizada a la satisfacci√≥n con estos aspectos del servicio.\n",
        "\n",
        "Tambi√©n se tienes otras variables que se encuentran sobredimensionadas en el rango  de [0, 5]: La variable ````Age```` muestra una distribuci√≥n aproximadamente sim√©trica centrada en los 40 a√±os. ````Flight Distance```` presenta un IQR amplio [414, 1744] y una cantidad considerable de outliers, indicando rutas con alta variabilidad. Finalmente, las variables de tiempo, ````Departure Delay in Minutes```` y ````Arrival Delay in Minutes````, muestran distribuciones marcadamente asim√©tricas. Aunque ambas se centran en torno a cero, existe una proporci√≥n significativa de valores extremos, con retrasos que superan los 1500 minutos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Crear figura\n",
        "fig = go.Figure()\n",
        "\n",
        "# Agregar un boxplot por cada variable\n",
        "for columna in df_numericas.columns:\n",
        "    if columna in ['Flight Distance', 'Departure Delay in Minutes', 'Arrival Delay in Minutes', 'Age']:\n",
        "        continue\n",
        "    fig.add_trace(go.Box(y=df_numericas[columna], name=columna, boxpoints='outliers'))\n",
        "\n",
        "# Ajustes de la figura\n",
        "fig.update_layout(\n",
        "    title=\"Distribuci√≥n Variables Nivel de Satisfacci√≥n\",\n",
        "    xaxis_title=\"Variables\",\n",
        "    yaxis_title=\"Valor\",\n",
        "    height=800,\n",
        "    width=1200,\n",
        "    title_x=0.5,\n",
        "    title_y=0.95,\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for columna in df_numericas.columns:\n",
        "    if columna not in ['Flight Distance', 'Departure Delay in Minutes', 'Arrival Delay in Minutes', 'Age']:\n",
        "        continue\n",
        "    fig = go.Figure()\n",
        "    #ignorar outliers\n",
        "    fig.add_trace(go.Box(y=df_numericas[columna], name=columna, boxpoints='outliers', showlegend=False))\n",
        "    fig.update_layout(\n",
        "        title=f\"Distribuci√≥n {columna}\",\n",
        "        xaxis_title=columna,\n",
        "        yaxis_title=\"Valor\",\n",
        "        height=400,\n",
        "        width=800,\n",
        "        title_x=0.5,\n",
        "        title_y=0.95,\n",
        "    )\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Bas√°ndose en los gr√°ficos, eval√∫e la necesidad de escalar los datos y explique el motivo de su decisi√≥n. [2 puntos]\n",
        "\n",
        "**Respuesta**: Al observar las distribuciones se hace evidente que los valores de las escalas var√≠an significativamente. Las variables: ```Flight Distance```, ```Departure Delay in Minutes```,```Arrival Delay in Minutes```, ```Age``` presentan rango muchas m√°s amplios (centenares de escala) mientras que las variables de nivel de satisfacci√≥n como ```Food and Drink``` estan restringidos a una escala de 1 a 5. Se hace necesario normalizar las escalas debido a que se utilizan m√©tricas de distancia para agrupar los datos, features con mayores rangos num√©ricos dominaran las m√©tricas y por tanto influira de desproporcionadamente en la agrupaci√≥n, incluso hasta el punto de obviar cualqueir otra feature. \n",
        "\n",
        "Por tanto, antes de aplicar reducci√≥n de dimensionalidad, es necesario escalar las variables, para que todas contribuyan de manera equitativa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Examine la correlaci√≥n entre las variables mediante un correlograma. [2 puntos]\n",
        "\n",
        "**Respuesta**: En general se observa una baja correlaci√≥n entre todas las variables, lo que sugiere una cierta independencia lineal entre las variables.```` Departure Delay in Minutes```` y ````Arrival Delay in Minutes```` (r ‚âà 0.97): relaci√≥n fuertemente positiva, esperable dada la dependencia directa entre ambos eventos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "# Calcular matriz de correlaci√≥n\n",
        "corr = df_numericas.corr(method='pearson', numeric_only=True)\n",
        "\n",
        "# Graficar correlograma\n",
        "fig = px.imshow(\n",
        "    corr,\n",
        "    text_auto='.2f',\n",
        "    aspect=\"auto\",\n",
        "    color_continuous_scale='Viridis',\n",
        "    title=\"Correlograma de variables num√©ricas\",\n",
        "    labels=dict(x=\"Variables\", y=\"Variables\", color=\"Correlaci√≥n\"),\n",
        "    x=corr.columns,\n",
        "    y=corr.columns,\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    width=1500,\n",
        "    height=1500,\n",
        "    margin=dict(l=50, r=50, t=50, b=50)\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. De acuerdo con los resultados obtenidos en 5, reduzca la dimensionalidad del conjunto de datos a cuatro variables, justificando su elecci√≥n respecto a las variables que decide eliminar. [2 puntos]\n",
        "\n",
        "**Respuesta**: Departure Delay in Minute, Age, Flight distance, Infligt Entertaiment. La primera variable tiene una alta correlacion con la tra variable temoral por lo que solo a√±adimos una de ellas. Lo mismo con age y X variable. Por √∫ltimo se puede boservar que existen agrupaciones locales entre las caracteristicas de valoraci√≥n, donde se eligen una representativa de los dos agrupacioens mas marcadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "4b6c047d994f40ea9e78a36a777042e0",
        "deepnote_cell_type": "markdown",
        "id": "PNGfTgtkrqC9"
      },
      "source": [
        "## 3. Preprocesamiento üé≠. [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "713b3f0e61dd4841bb5b38c730d344d5",
        "deepnote_cell_type": "markdown",
        "id": "6RZD0fMNrqC-"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://media4.giphy.com/media/vWst8QUOKAot6MHEZe/giphy.gif?cid=6c09b952gm5xylrj4k5caq2slgwivx9azbgb0ox297sk5zjx&ep=v1_internal_gif_by_id&rid=giphy.gif&ct=g\" width=400>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "98400c7b5fec4af193eec3601f53891e",
        "deepnote_cell_type": "markdown",
        "id": "J6d4VEOTrqC-"
      },
      "source": [
        "Tras quedar satisfecho con los resultados presentados en el punto 2, el due√±o de la empresa ha solicitado que se preprocesen los datos mediante un `pipeline`. Es crucial que este proceso tenga en cuenta las observaciones derivadas de los an√°lisis anteriores. Adicionalmente, ha expresado su inter√©s en visualizar el conjunto de datos en un gr√°fico de dos o tres dimensiones.\n",
        "\n",
        "Bas√°ndose en los an√°lisis realizados anteriormente:\n",
        "1. Cree un `pipeline` que incluya PCA, utilizando las consideraciones mencionadas previamente para proyectar los datos a dos dimensiones. [4 puntos]\n",
        "2. Grafique los resultados obtenidos y comente lo visualizado. [6 puntos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_numericas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "paDSaGoq0OUp"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "ad1e70818ad748638ca0927b07a76125",
        "deepnote_cell_type": "code",
        "id": "gBYG238wrqC-"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler \n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "numerical_columns = ['Flight Distance', 'Departure Delay in Minutes', 'Arrival Delay in Minutes', 'Age']\n",
        "# numerical_columns = ['Flight Distance', 'Departure Delay in Minutes', 'Arrival Delay in Minutes', 'Ease of Online booking']\n",
        "# numerical_columns = ['Flight Distance', 'Departure Delay in Minutes', 'Arrival Delay in Minutes', 'Checkin service']\n",
        "\n",
        "n_dims = 2\n",
        "\n",
        "def PCA_pipeline(df_, n_dims, numerical_columns):\n",
        "    \n",
        "    # Preprocesamiento num√©rico\n",
        "    numeric_pipeline = Pipeline(steps=[\n",
        "        ('imputer', SimpleImputer(strategy='mean')),\n",
        "        ('scaler', StandardScaler())\n",
        "    ])\n",
        "\n",
        "    # ColumnTransformer (solo para aplicar preprocessing)\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numeric_pipeline, numerical_columns)\n",
        "        ],\n",
        "        remainder='drop',\n",
        "        verbose_feature_names_out=False\n",
        "    )\n",
        "\n",
        "    # Pipeline completo: preprocesamiento + PCA\n",
        "    full_pipeline = Pipeline(steps=[\n",
        "        ('preprocessing', preprocessor),\n",
        "        ('pca', PCA(n_components=n_dims))\n",
        "    ]).set_output(transform='pandas')\n",
        "\n",
        "    # Aplicar pipeline al dataset\n",
        "    df_pca = full_pipeline.fit_transform(df_)\n",
        "    contr_features_pca = full_pipeline.named_steps['pca'].components_\n",
        "    print(f\"Componentes PCA: {contr_features_pca}\")\n",
        "    print(f\"Varianza explicada: {full_pipeline.named_steps['pca'].explained_variance_ratio_}\")\n",
        "    return df_pca, full_pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PCA 2DIM\n",
        "import plotly.express as px\n",
        "\n",
        "df_pca, pca_pipeline = PCA_pipeline(df_numericas, n_dims=2,numerical_columns=numerical_columns)\n",
        "fig = px.scatter(\n",
        "    df_pca,\n",
        "    x='pca1',\n",
        "    y='pca0',\n",
        "    title=\"Proyecci√≥n PCA a 2 dimensiones\",\n",
        "    labels={'PC1': 'Componente Principal 1', 'PC2': 'Componente Principal 2'},\n",
        "    opacity=1,\n",
        "    width=800,\n",
        "    height=600,\n",
        ")\n",
        "\n",
        "fig.update_traces(marker=dict(size=2))\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_pca, pca_pipeline = PCA_pipeline(df_numericas, n_dims=3, numerical_columns=numerical_columns)\n",
        "fig = px.scatter_3d(\n",
        "    df_pca,\n",
        "    x='pca2',\n",
        "    y='pca0',\n",
        "    z='pca1',\n",
        "    color='pca0',\n",
        "    title=\"Proyecci√≥n PCA a 3 dimensiones\",\n",
        "    labels={'PC1': 'Componente Principal 1', 'PC2': 'Componente Principal 2', 'PC3': 'Componente Principal 3'},\n",
        "    opacity=0.5,\n",
        "    width=1500,\n",
        "    height=1000,\n",
        ")\n",
        "fig.update_traces(marker=dict(size=3), selector=dict(mode='markers'))\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Grafique los resultados obtenidos y comente lo visualizado. [6 puntos]\n",
        "\n",
        "**Respuesta**: Como se apreica en el primer gr√°fico al reducir a las dos componentes principales se obserba una distribuci√≥n concentrada hacia pca0 bajos y que se extiende sobre pca1. A pesar de ellos, solo usando las dos componentes principales no es posibles identificar agrupaciones en los datos, ni tampoco se logra capturar su comportamiento. En cambio al a√±adir la tercera componente se puede observar relaciones interesantes como una mayor disperci√≥n para pca0 altos, y una relacion proporcional entre pca1 y pc2, revelando ciertos patrones de comportamiento que no eran perceptibles en la proyecci√≥n bidimensional."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "bd281470d3054764a63d857cfa7d52a6",
        "deepnote_cell_type": "text-cell-h2",
        "formattedRanges": [],
        "id": "7ENoOtIIrqC_"
      },
      "source": [
        "## 4. Outliers üö´üôÖ‚Äç‚ôÄÔ∏è‚ùåüôÖ‚Äç‚ôÇÔ∏è [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "db89e9c9f35c44abbd8991180226c0ea",
        "deepnote_cell_type": "markdown",
        "id": "fbGw6Sa-rqC_"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://joachim-gassen.github.io/images/ani_sim_bad_leverage.gif\" width=250>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "3e2f59fa12954641af7a854a4e203694",
        "deepnote_cell_type": "markdown",
        "id": "nl_ccu9brqDA"
      },
      "source": [
        "Con el objetivo de mantener la claridad en su an√°lisis, Don Sergio le ha solicitado entrenar un modelo que identifique pasajeros con comportamientos altamente at√≠picos.\n",
        "\n",
        "1. Utilice `IsolationForest` para clasificar las anomal√≠as del dataset (sin aplicar PCA), configurando el modelo para que s√≥lo el 1% de los datos sean considerados an√≥malos. Aseg√∫rese de integrar esta tarea dentro de un `pipeline`. [3 puntos]\n",
        "\n",
        "2. Visualice los resultados en el gr√°fico de dos dimensiones previamente creado. [3 puntos]\n",
        "\n",
        "3. ¬øC√≥mo evaluar√≠a el rendimiento de su modelo en la detecci√≥n de anomal√≠as? [4 puntos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "numeric_features = df.select_dtypes(include='number').drop(columns=['id']).columns.to_list()\n",
        "numeric_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5cS1FR00NlF"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Definir columnas num√©ricas\n",
        "numeric_features = numerical_columns\n",
        "\n",
        "# Crear pipeline para preprocesamiento num√©rico\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', MinMaxScaler()),\n",
        "])\n",
        "\n",
        "# Preprocesador completo\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features)\n",
        "    ],\n",
        "    remainder='drop',\n",
        "    verbose_feature_names_out=False\n",
        "    )\n",
        "\n",
        "# Pipeline completo con Isolation Forest\n",
        "isolation_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('isolation', IsolationForest(contamination=0.01, random_state=SEED))\n",
        "])\n",
        "\n",
        "# Ajustar el modelo\n",
        "isolation_pipeline.fit(df[numeric_features])\n",
        "\n",
        "# Predecir anomal√≠as (-1 para anomal√≠as, 1 para normales)\n",
        "anomalies=isolation_pipeline.predict(df[numeric_features])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_pca, _ = PCA_pipeline(df, n_dims=3, numerical_columns=numerical_columns)\n",
        "df_pca['anomaly'] = anomalies\n",
        "df_pca['anomaly'] = df_pca['anomaly'].map({1: 'Normal', -1: 'Anomal√≠a'})\n",
        "\n",
        "fig = px.scatter_3d(\n",
        "    df_pca,\n",
        "    x='pca2',\n",
        "    y='pca1',\n",
        "    z='pca0',\n",
        "    color='anomaly',\n",
        "    color_discrete_map={'Normal': 'blue', 'Anomal√≠a': 'red'},\n",
        "    title=\"Proyecci√≥n PCA a 3 dimensiones\",\n",
        "    labels={'PC1': 'Componente Principal 1', 'PC2': 'Componente Principal 2', 'PC3': 'Componente Principal 3'},\n",
        "    opacity=1,\n",
        "    width=1500,\n",
        "    height=1000,\n",
        ")\n",
        "fig.update_traces(marker=dict(size=2), selector=dict(mode='markers'))\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Obtener las componentes principales (usando el pipeline PCA creado anteriormente)\n",
        "df_pca, _ = PCA_pipeline(df, n_dims=2, numerical_columns=numerical_columns)\n",
        "\n",
        "# A√±adir las predicciones de anomal√≠as al dataframe\n",
        "df_pca['anomaly'] = anomalies\n",
        "df_pca['anomaly'] = df_pca['anomaly'].map({1: 'Normal', -1: 'Anomal√≠a'})\n",
        "\n",
        "# Crear el gr√°fico\n",
        "fig = px.scatter(\n",
        "    df_pca,\n",
        "    x='pca0',\n",
        "    y='pca1',\n",
        "    color='anomaly',\n",
        "    color_discrete_map={'Normal': 'blue', 'Anomal√≠a': 'red'},\n",
        "    title=\"Detecci√≥n de Anomal√≠as en Proyecci√≥n PCA 2D\",\n",
        "    labels={'pca0': 'Componente Principal 1', 'pca1': 'Componente Principal 2'},\n",
        "    opacity=0.7,\n",
        "    width=800,\n",
        "    height=600\n",
        ")\n",
        "\n",
        "fig.update_traces(\n",
        "    marker=dict(size=8, line=dict(width=1, color='DarkSlateGrey')),\n",
        "    selector=dict(mode='markers')\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    legend_title_text='Clasificaci√≥n',\n",
        "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1)\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Obtener scores de anomal√≠a (entre m√°s bajo, m√°s an√≥malo)\n",
        "anomalies_scores = isolation_pipeline.decision_function(df[numeric_features])\n",
        "df_s = df.copy()\n",
        "df_s['anomaly_score']= anomalies_scores\n",
        "# Visualizar distribuci√≥n de scores\n",
        "fig = px.histogram(df, x=anomalies_scores, nbins=50, \n",
        "                   title='Distribuci√≥n de Scores de Anomal√≠a',\n",
        "                   labels={'anomaly_score': 'Score de Anomal√≠a'},\n",
        "                   width=700, height=500)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Porcentaje de anomal√≠as detectadas\n",
        "anomalies_pct = (anomalies < 0).mean() * 100\n",
        "print(f\"El modelo clasifica como an√≥malos el {anomalies_pct:.2f}% de los datos\")\n",
        "\n",
        "\n",
        "most_anomalous = df_s.nsmallest(5, 'anomaly_score')\n",
        "print(\"\\n5 puntos m√°s an√≥malos:\")\n",
        "most_anomalous[ numeric_features + ['anomaly_score']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. ¬øC√≥mo evaluar√≠a el rendimiento de su modelo en la detecci√≥n de anomal√≠as? [4 puntos]\n",
        "\n",
        "**Respuesta**: Para evluar el rendimiento de detecci√≥n de anomal√≠as se construye el histograma sobre el ```anomaly_score``` adjunto considerando 50 bins. El m√©todo decision_function le da una puntuaci√≥n a cada data para ver que tan an√≥malo es, donde los valores que son menores a 0 son clasificados como m√°s an√≥malos. Por tanto los valores bajo el cero en el gr√°fico son considerados anomalos. Cualitativamente en el dataframe most_anomaous se aprecian los 5 pasajeros con el menos score de anomaly_score, donde se obervan comportamientos contradictorios en su calificaci√≥n de servicios. Por ejemplo, en las columnas de servicio de vuelo, comodidad del asiento y limpieza los puntuaron con la menos clasificaci√≥n, mientras que los servicios a bordo y entrentenimiento se clasifican con la mayor puntuaci√≥n. Este comportameinto si bien puede ser factible, no se ve en los pasajeros, por tanto hace sentido su clasificaci√≥n."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "3871e2fe5bdd422dbdbfaebf75503ae3",
        "deepnote_cell_type": "markdown",
        "id": "zQFTklmVrqDB"
      },
      "source": [
        "## 5. M√©tricas de Desempe√±o üöÄ [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "236333de6dd445c182aefcc507589325",
        "deepnote_cell_type": "markdown",
        "id": "YpNj4wbPrqDB"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://giffiles.alphacoders.com/219/219081.gif\" width=300>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "a7e1ceb91be94b1da2ab8be97dfac999",
        "deepnote_cell_type": "markdown",
        "id": "CR3hzRxrrqDB"
      },
      "source": [
        "Motivado por incrementar su fortuna, Don Sergio le solicita entrenar un modelo que le permita segmentar a los pasajeros en grupos distintos, con el objetivo de optimizar las diversas campa√±as de marketing dise√±adas por su equipo. Para ello, le se pide realizar las siguientes tareas:\n",
        "\n",
        "1. Utilizar el modelo **Gaussian Mixture** y explore diferentes configuraciones de n√∫mero de cl√∫sters, espec√≠ficamente entre 3 y 8. Aseg√∫rese de integrar esta operaci√≥n dentro de un `pipeline`. [4 puntos]\n",
        "2. Explique cu√°l ser√≠a el criterio adecuado para seleccionar el n√∫mero √≥ptimo de cl√∫sters. **Justifique de forma estadistica y a traves de gr√°ficos.** [6 puntos]\n",
        "\n",
        "> **HINT:** Se recomienda investigar sobre los criterios AIC y BIC para esta tarea."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "numeric_features = df.select_dtypes(include='number').drop(columns=['id']).columns.to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "numeric_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jt_T_zTg0MXB"
      },
      "source": [
        "1. Utilizar el modelo Gaussian Mixture y explore diferentes configuraciones de n√∫mero de cl√∫sters, espec√≠ficamente entre 3 y 8. Aseg√∫rese de integrar esta operaci√≥n dentro de un pipeline. [4 puntos]\n",
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "6d3d1bb3fda14321984466d9101a775a",
        "deepnote_cell_type": "code",
        "id": "5GeUb9J3rqDB"
      },
      "outputs": [],
      "source": [
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "# Definir columnas num√©ricas relevantes para la segmentaci√≥n\n",
        "numeric_features = ['Age', 'Flight Distance', 'Inflight wifi service', \n",
        "                   'Food and drink', 'Seat comfort', 'Inflight entertainment',\n",
        "                   'On-board service', 'Cleanliness']\n",
        "\n",
        "# Crear pipeline para preprocesamiento num√©rico\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Preprocesador completo\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features)\n",
        "    ])\n",
        "\n",
        "# Evaluar diferentes n√∫meros de clusters (de 3 a 8)\n",
        "n_components_range = range(3, 9)\n",
        "models = {}\n",
        "aics = []\n",
        "bics = []\n",
        "\n",
        "for n_components in n_components_range:\n",
        "    # Crear pipeline con GMM\n",
        "    gmm_pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('gmm', GaussianMixture(n_components=n_components, \n",
        "                               covariance_type='full', \n",
        "                               random_state=42))\n",
        "    ])\n",
        "    \n",
        "    # Ajustar el modelo\n",
        "    gmm_pipeline.fit(df[numeric_features])\n",
        "    models[n_components] = gmm_pipeline\n",
        "    \n",
        "    # Calcular m√©tricas\n",
        "    aics.append(gmm_pipeline.named_steps['gmm'].aic(df[numeric_features]))\n",
        "    bics.append(gmm_pipeline.named_steps['gmm'].bic(df[numeric_features]))\n",
        "    \n",
        "    print(f\"GMM con {n_components} clusters - AIC: {aics[-1]:.2f}, BIC: {bics[-1]:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gr√°fico de AIC y BIC\n",
        "fig = go.Figure()\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=list(n_components_range),\n",
        "    y=aics,\n",
        "    mode='lines+markers',\n",
        "    name='AIC',\n",
        "    line=dict(color='royalblue', width=2)\n",
        "))\n",
        "\n",
        "fig.add_trace(go.Scatter(\n",
        "    x=list(n_components_range),\n",
        "    y=bics,\n",
        "    mode='lines+markers',\n",
        "    name='BIC',\n",
        "    line=dict(color='firebrick', width=2)\n",
        "))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Criterios AIC y BIC para diferentes n√∫meros de clusters',\n",
        "    xaxis_title='N√∫mero de clusters',\n",
        "    yaxis_title='Valor del criterio',\n",
        "    width=800,\n",
        "    height=500,\n",
        "    showlegend=True\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Explique cu√°l ser√≠a el criterio adecuado para seleccionar el n√∫mero √≥ptimo de cl√∫sters. Justifique de forma estadistica y a traves de gr√°ficos. [6 puntos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Seleccionar el mejor modelo seg√∫n BIC (m√°s conservador)\n",
        "optimal_n_components = n_components_range[np.argmin(bics)]\n",
        "print(f\"\\nN√∫mero √≥ptimo de clusters seg√∫n BIC: {optimal_n_components}\")\n",
        "\n",
        "# Obtener el mejor modelo\n",
        "best_gmm = models[optimal_n_components]\n",
        "\n",
        "# Asignar clusters a los datos\n",
        "df['cluster'] = best_gmm.predict(df[numeric_features])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Proyectar a 2D usando el pipeline PCA anterior\n",
        "df_pca, _ = PCA_pipeline(df, n_dims=2, numerical_columns=numeric_features)\n",
        "\n",
        "# A√±adir la asignaci√≥n de clusters\n",
        "df_pca['cluster'] = df['cluster'].astype(str)\n",
        "\n",
        "# Crear gr√°fico\n",
        "fig = px.scatter(\n",
        "    df_pca,\n",
        "    x='pca0',\n",
        "    y='pca1',\n",
        "    color='cluster',\n",
        "    title=f\"Segmentaci√≥n de Clientes con GMM ({optimal_n_components} clusters)\",\n",
        "    labels={'pca0': 'Componente Principal 1', 'pca1': 'Componente Principal 2'},\n",
        "    opacity=0.7,\n",
        "    width=800,\n",
        "    height=600\n",
        ")\n",
        "\n",
        "fig.update_traces(\n",
        "    marker=dict(size=8, line=dict(width=1, color='DarkSlateGrey')),\n",
        "    selector=dict(mode='markers')\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    legend_title_text='Cluster',\n",
        "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1)\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analizar caracter√≠sticas por cluster\n",
        "cluster_stats = df.groupby('cluster')[numeric_features].mean().T\n",
        "print(\"\\nMedias por cluster:\")\n",
        "print(cluster_stats)\n",
        "\n",
        "# Visualizaci√≥n de las medias por cluster\n",
        "fig = go.Figure()\n",
        "\n",
        "for cluster in sorted(df['cluster'].unique()):\n",
        "    fig.add_trace(go.Bar(\n",
        "        x=numeric_features,\n",
        "        y=cluster_stats[cluster],\n",
        "        name=f'Cluster {cluster}'\n",
        "    ))\n",
        "\n",
        "fig.update_layout(\n",
        "    title='Medias de caracter√≠sticas por cluster',\n",
        "    xaxis_title='Caracter√≠sticas',\n",
        "    yaxis_title='Valor medio (escalado)',\n",
        "    barmode='group',\n",
        "    width=1000,\n",
        "    height=600\n",
        ")\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. An√°lisis de resultados üìä [10 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "953b5ad01a704b50b899db7176d1b7b2",
        "deepnote_cell_type": "markdown",
        "id": "I1yNa111rqDC"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://www.icegif.com/wp-content/uploads/2021/12/icegif-1407.gif\" width=300>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "cell_id": "fd90e2f135404353ac0b5ab844936ca7",
        "deepnote_cell_type": "markdown",
        "id": "dg0Qx4RZrqDC"
      },
      "source": [
        "Una vez identificado el n√∫mero √≥ptimo de cl√∫sters, se le pide realizar lo siguiente:\n",
        "\n",
        "1. Utilizar la proyecci√≥n en dos dimensiones para visualizar cada cl√∫ster claramente. [2 puntos]\n",
        "\n",
        "2. ¬øEs posible distinguir claramente entre los cl√∫sters generados? [2 puntos]\n",
        "\n",
        "3. Proporcionar una descripci√≥n breve de cada cl√∫ster utilizando estad√≠sticas descriptivas b√°sicas, como la media y la desviaci√≥n est√°ndar, para resumir las caracter√≠sticas de las variables utilizadas en estos algoritmos. [2 puntos]\n",
        "\n",
        "4. Proceda a visualizar los cl√∫sters en tres dimensiones para una perspectiva m√°s detallada. [2 puntos]\n",
        "\n",
        "5. ¬øC√≥mo afecta esto a sus conclusiones anteriores? [2 puntos]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRN0zZip0IMB"
      },
      "source": [
        "**Respuestas:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cell_id": "9abf4dbc643e40cebe99fcb1ff3ff413",
        "deepnote_cell_type": "code",
        "id": "XmZrz15GrqDC"
      },
      "outputs": [],
      "source": [
        "# Proyecci√≥n a 2D usando PCA (usando el pipeline anterior)\n",
        "df_pca_2d, _ = PCA_pipeline(df, n_dims=2, numerical_columns=numeric_features)\n",
        "df_pca_2d['cluster'] = df['cluster'].astype(str)\n",
        "\n",
        "# Crear gr√°fico 2D\n",
        "fig_2d = px.scatter(\n",
        "    df_pca_2d,\n",
        "    x='pca0',\n",
        "    y='pca1',\n",
        "    color='cluster',\n",
        "    title=f\"Segmentaci√≥n de Clientes (2D) - {optimal_n_components} Clusters\",\n",
        "    labels={'pca0': 'Componente Principal 1', 'pca1': 'Componente Principal 2'},\n",
        "    opacity=0.7,\n",
        "    width=800,\n",
        "    height=600,\n",
        "    color_discrete_sequence=px.colors.qualitative.Plotly\n",
        ")\n",
        "\n",
        "fig_2d.update_traces(\n",
        "    marker=dict(size=8, line=dict(width=0.5, color='DarkSlateGrey')),\n",
        "    selector=dict(mode='markers')\n",
        ")\n",
        "\n",
        "fig_2d.update_layout(\n",
        "    legend_title_text='Cluster',\n",
        "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\", x=1)\n",
        ")\n",
        "\n",
        "fig_2d.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. ¬øEs posible distinguir claramente entre los cl√∫sters generados? [2 puntos]\n",
        "\n",
        "No es claro distinguir cu√°les son los distintos clusters generados ya que se solapan entre s√≠. Se dificulta la visualizaci√≥n al ser en dos dimensiones solamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Proporcionar una descripci√≥n breve de cada cl√∫ster utilizando estad√≠sticas descriptivas b√°sicas, como la media y la desviaci√≥n est√°ndar, para resumir las caracter√≠sticas de las variables utilizadas en estos algoritmos. [2 puntos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "features = ['Age', 'Flight Distance', 'Inflight wifi service', 'Food and drink',\n",
        "            'Seat comfort', 'Inflight entertainment', 'On-board service', 'Cleanliness']\n",
        "\n",
        "cluster_stats = df.groupby('cluster')[features].agg(['mean', 'std'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cluster_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for cluster in sorted(df['cluster'].unique()):\n",
        "    print(f\"\\nCluster {cluster}:\")\n",
        "    \n",
        "    means = cluster_stats.loc[cluster].xs('mean', level=1)\n",
        "    stds = cluster_stats.loc[cluster].xs('std', level=1)\n",
        "    \n",
        "    top_features = means.nlargest(3)\n",
        "    \n",
        "    for feature in top_features.index:\n",
        "        mean_val = means[feature]\n",
        "        std_val = stds[feature]\n",
        "        print(f\"- {feature}: {mean_val:.2f} ¬± {std_val:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Proporcionar una descripci√≥n breve de cada cl√∫ster utilizando estad√≠sticas descriptivas b√°sicas, como la media y la desviaci√≥n est√°ndar, para resumir las caracter√≠sticas de las variables utilizadas en estos algoritmos. [2 puntos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Transponer para facilitar comparaciones entre clusters\n",
        "mean_df = cluster_stats.xs('mean', axis=1, level=1).T\n",
        "std_df = cluster_stats.xs('std', axis=1, level=1).T\n",
        "\n",
        "for cluster in mean_df.columns:\n",
        "    print(f\"\\nüîπ Cluster {cluster}:\")\n",
        "    \n",
        "    means = mean_df[cluster]\n",
        "    stds = std_df[cluster]\n",
        "    \n",
        "    # Top 3 caracter√≠sticas m√°s altas y m√°s bajas\n",
        "    top = means.sort_values(ascending=False).head(3)\n",
        "    bottom = means.sort_values().head(3)\n",
        "\n",
        "    print(f\"Este cl√∫ster se caracteriza por:\")\n",
        "    for feat in top.index:\n",
        "        print(f\"  - Alta media en **{feat}** ({means[feat]:.2f} ¬± {stds[feat]:.2f})\")\n",
        "    for feat in bottom.index:\n",
        "        print(f\"  - Baja media en **{feat}** ({means[feat]:.2f} ¬± {stds[feat]:.2f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Proceda a visualizar los cl√∫sters en tres dimensiones para una perspectiva m√°s detallada. [2 puntos]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_pca = df_pca.copy()\n",
        "df_pca['cluster'] = df['cluster'].astype(str)  # Convertimos a string para colores categ√≥ricos\n",
        "\n",
        "# Visualizaci√≥n con Plotly\n",
        "fig = px.scatter_3d(\n",
        "    df_pca,\n",
        "    x='pca2',\n",
        "    y='pca1',\n",
        "    z='pca0',\n",
        "    color='cluster',  # ‚Üê aqu√≠ cambiamos\n",
        "    title=\"Proyecci√≥n PCA a 3 dimensiones por Cluster\",\n",
        "    labels={'pca0': 'Componente Principal 1', 'pca1': 'Componente Principal 2', 'pca2': 'Componente Principal 3'},\n",
        "    opacity=0.5,\n",
        "    width=1500,\n",
        "    height=1000,\n",
        ")\n",
        "\n",
        "fig.update_traces(marker=dict(size=1), selector=dict(mode='markers'))\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "¬øC√≥mo afecta esto a sus conclusiones anteriores? [2 puntos]\n",
        "\n",
        "Se pueden visualizar mucho mejor los clusters en comparaci√≥n al PCA realizado en 2 dimensiones. Al tener 3 dimensiones, se puede rotar y visualizar mejor cada dato y su pertenencia al grupo correspondiente, as√≠ como un cierto orden en cada uno de los clusters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Mucho √©xito!\n",
        "\n",
        "<center>\n",
        "<img src=\"https://i.pinimg.com/originals/55/3d/42/553d42bea9b10e0662a05aa8726fc7f4.gif\" width=300>"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "7cb425aec99b4079954fd707109c42c3",
    "deepnote_persisted_session": {
      "createdAt": "2024-04-26T06:15:51.197Z"
    },
    "kernelspec": {
      "display_name": "lab",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
